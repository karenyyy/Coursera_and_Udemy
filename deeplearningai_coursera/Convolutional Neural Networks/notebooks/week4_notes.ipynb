{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week4 notes.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "cs0B6tIJ-S6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Face Recognition"
      ]
    },
    {
      "metadata": {
        "id": "RIdkZd-I-S6R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### face verification vs. face recognition\n",
        "\n",
        "Verification\n",
        "- Input image, name/ID\n",
        "- Output whether the input image is that of the claimed person\n",
        "\n",
        "Recognition\n",
        "- Has a database of K persons\n",
        "- Get an input image\n",
        "- Output ID if the image is any of the K persons (or 'not recognized')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cbmVnBd3-S6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One-shot Learning\n",
        "\n",
        "\n",
        "Learning from one example to recognize the person again\n",
        "\n",
        "### Learning a 'similarity function\n",
        "\n",
        "$$d(img1, img2) = \\text{degree of difference between images}$$\n",
        "\n",
        "\n",
        "$$\\text{If } d(img1, im2) \\le x, \\Rightarrow \\text{ same image }$$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9IzAhQ01-S6Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Siamese Network\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kaWB-ZiqMIqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Triplet Loss\n",
        "\n",
        "\n",
        "- A: Anchor picture\n",
        "- P: Positive picture\n",
        "- N: Negative picture\n",
        "\n",
        "$$\\text{Goal: }\\frac{||f(A） － f(p)||^2}{d(A,p)} \\le \\frac{||f(A） － f(N)||^2}{d(A,N)}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Given 3 images, A, P, N\n",
        "\n",
        "$$L(A, P, N) = \\max||f(A) - f(P)||^2-||f(A) - f(N)||^2 +\\alpha, 0)$$\n",
        "\n",
        "\n",
        "$$J = \\sum^m_{i=1} L(A^{(i)}, P^{(i)}, N^{(i)})$$\n",
        "\n",
        "\n",
        "use __Gradient Descent__\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "n0DlJgS-RFOx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Turn the last the fc layer of face verification into a binary classification problem\n",
        "\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/46.png)\n",
        "\n",
        "\n",
        "\n",
        "$$\\hat y = \\sigma \\left ( \\sum^{128}_{k=1} w_i |f(x^{(i)})_k - f(x^{(j)})_k| + b\\right) $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5zU_H3EPYbgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Style Transfer\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sokJv2vrYgHd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "what are the deeper layers of CNN doing?\n",
        "\n",
        "__Each hidden unit pinpointing one feature of the input picture:__\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/47.png)\n",
        "\n",
        "\n",
        "__Each 3x3 grid cell represents one feature captured by the CNN__\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/48.png)\n",
        "\n",
        "\n",
        "As the layer gets deeper, it captures more complex features.\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/49.png)\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/50.png)\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/51.png)\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/52.png)\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/53.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "pjrX5wx-iTFD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Cost Function"
      ]
    },
    {
      "metadata": {
        "id": "E8F17YOkizmK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$$J(G) = \\alpha J_{content}(C, G) +\\beta J_{style}(S, G)$$\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/54.png)\n",
        "\n",
        "\n",
        "\n",
        "#### Find the generated image G\n",
        "\n",
        "\n",
        "- Initiate G randomly\n",
        "\n",
        "  - G: 100x100x3\n",
        "\n",
        "- Use gradient descent to minimize $J(G)$\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/55.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4xvCB5ZlkrVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Content cost function\n",
        "\n",
        "\n",
        "- use hidden layer $l$ to compute content cost\n",
        "- use __pre-trained__ ConvNet (VGG)\n",
        "- let $a^{[l](C)}$ and $a^{[l](G)}$ be the activation of layer $l$ on the images\n",
        "  - if $a^{[l](C)}$ and $a^{[l](G)}$ are similar, both images have similar content\n",
        "\n",
        "$$J_{content} (C, G) = \\frac{1}{2}||a^{[l](C)} - a^{[l](G)}||^2$$\n"
      ]
    },
    {
      "metadata": {
        "id": "fwdb8lLUl864",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Style cost function\n",
        "\n",
        "\n",
        "- use layer $l$'s activation to measure 'style'\n",
        "- define style as correlation between activations across channels\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/56.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/57.png)\n",
        "\n",
        "\n",
        "\n",
        "__Why does the correlations between activations across channels represent 'style'???__\n",
        "\n",
        "example:\n",
        "\n",
        "- red channel:  the 2nd neuron\n",
        "- yellow channel: the 4th neuron\n",
        "\n",
        "\n",
        "__if these 2 channels are highly correlated, then that means whatever part of image has this type of subtle vertical texture (2nd neuron), that part of the image will probably have the orange-ish tint (4th neuron)__\n",
        "\n",
        "\n",
        "#### And the degree of correlation provides one way of measuring how  often these different high level features such direction pattern or texture, how often they occur and how often they occur together in different parts of an image.\n",
        "\n",
        "\n",
        "- then we can measure the degree to which in the generated image, one channel is correlated ot uncorrelated with the another channel, that  tells us how similar is the style of the generated image to the style of the input style image\n",
        "\n",
        "### Style Matrix\n",
        "\n",
        "$$\\text{Let } a^{[L]}_{i,j,k} = \\text{ activation at } (i,j,k)$$\n",
        "\n",
        "$$G^{[l]} = n_c^{[l]} \\text{ x } n_c^{[l]}$$\n",
        "\n",
        "\n",
        "\n",
        "$$G_{kk'}^{[l](S)} = \\sum_{i=1}^{n_{h}^{[l]}} \\sum_{j=1}^{n_w^{[l]}} a^{[L](S)}_{i,j,k} a^{[L](S)}_{i,j,k'} , \\text{ where } k, k' = 1,..., n_c^{[l]}$$\n",
        "\n",
        "\n",
        "\n",
        "$$G_{kk'}^{[l](G)} = \\sum_{i=1}^{n_{h}^{[l]}} \\sum_{j=1}^{n_w^{[l]}} a^{[L](G)}_{i,j,k} a^{[L](G)}_{i,j,k'} , \\text{ where } k, k' = 1,..., n_c^{[l]}$$\n",
        "\n",
        "\n",
        "\n",
        "__What G is doing is summing over the different positions that the image over the height and width and just multiplying the activations together of the channels k and k'__\n",
        "\n",
        "\n",
        "\n",
        "$$J_{style}^{[l]}(S, G) = \\frac{1}{(2n_h^{[l]}n_w^{[l]}n_c^{[l]})^2} ||G_{kk'}^{[l](S)}  - G_{kk'}^{[l](G)} ||^2_F$$\n",
        "\n",
        "\n",
        "$$=\\frac{1}{(2n_h^{[l]}n_w^{[l]}n_c^{[l]})^2} \\sum_k \\sum_{k'} (G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)} )^2$$\n",
        "\n",
        "\n",
        "It turns out that you get more visually pleasing results if you use the style cost function __from multiple different layers__.\n",
        "\n",
        "\n",
        "#### Overall style cost function\n",
        "\n",
        "$$J_{style}(S, G) = \\sum_l \\lambda^{[l]} J_{style}^{[l]}(S, G)$$\n",
        "\n",
        "\n",
        "__It allows you to use different layers in a neural network, including early ones which measures relatively simpler low level features like edges as well as later layers which measure high level features and cause a NN to take both high and low level correlations into account when computing style.__\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}