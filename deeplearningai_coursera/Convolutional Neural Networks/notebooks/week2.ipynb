{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05bfEF_iByF-"
   },
   "source": [
    "## Classic Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SA1VcmEK2jq"
   },
   "source": [
    "### Lenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fH_Q4q_CHII"
   },
   "source": [
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/22.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H7MMB4bYI5mU"
   },
   "outputs": [],
   "source": [
    "## Lenet\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "## mnist dataset\n",
    "train_x = train_set[0].reshape((-1,28,28,1))\n",
    "train_y = to_categorical(train_set[1])\n",
    " \n",
    "valid_x = valid_set[0].reshape((-1,28,28,1))\n",
    "valid_y = to_categorical(valid_set[1])\n",
    " \n",
    "test_x = test_set[0].reshape((-1,28,28,1))\n",
    "test_y = to_categorical(test_set[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(5,5),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model.evaluate(test_x,test_y,batch_size=20,verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:71: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:74: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "## Lenet Pytorch\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epoches = 50\n",
    "\n",
    "trans_img = transforms.ToTensor()\n",
    "\n",
    "trainset = MNIST('./data', train=True, transform=trans_img, download=True)\n",
    "testset = MNIST('./data', train=False, transform=trans_img, download=True)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# build network\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 120),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "lenet = Lenet()\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = optim.SGD(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "# train\n",
    "for i in range(epoches):\n",
    "    since = time.time()\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in trainloader:\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = lenet(img)\n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.data[0]\n",
    "\n",
    "    running_loss /= len(trainset)\n",
    "    running_acc /= len(trainset)\n",
    "    print(\"[%d/%d] Loss: %.5f, Acc: %.2f, Time: %.1f s\" %(i+1, epoches, running_loss, 100*running_acc, time.time()-since))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6WFfOxSKIpcI"
   },
   "source": [
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/21.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V6lZVE6GUqC-"
   },
   "outputs": [],
   "source": [
    "## AlexNet\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aGjgeTrXIti4"
   },
   "source": [
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/22.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mK7hkp0NIwPO"
   },
   "source": [
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/23.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6abQQOGIymu"
   },
   "source": [
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/24.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wG7-QJiUI03S"
   },
   "source": [
    "\n",
    "> Why do residual networks work?\n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/25.png)\n",
    "\n",
    "\n",
    "\n",
    "> What would be the problems in very deep plain net __without the residual of the skip connection__?\n",
    "\n",
    "\n",
    "__It is very difficult for the network to choose parameters that learn even the identity function which is why a lot of layers end up making the result worse rather than making the result better__\n",
    "\n",
    "__And residual network works since it is very easy for the extra layers to learn the identity function and then a lot of the time may even improve the performance__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/26.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wToY8D4zIoei"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "week2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
