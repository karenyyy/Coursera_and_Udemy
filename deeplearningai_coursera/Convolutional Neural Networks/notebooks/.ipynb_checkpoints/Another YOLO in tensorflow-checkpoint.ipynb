{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rs-pctuZ4uqy"
   },
   "source": [
    "## YOLO 试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1685,
     "status": "ok",
     "timestamp": 1531842004494,
     "user": {
      "displayName": "Jiarong Ye",
      "photoUrl": "//lh4.googleusercontent.com/-q7b8noGUXEk/AAAAAAAAAAI/AAAAAAAAAPE/c6ZjOOV9LiQ/s50-c-k-no/photo.jpg",
      "userId": "110838105291424103468"
     },
     "user_tz": 240
    },
    "id": "YdnxMbmK9fOO",
    "outputId": "f2cd2ab3-005c-4671-8551-682a9b3c82dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolo_tensorflow'...\n",
      "remote: Counting objects: 117, done.\u001b[K\n",
      "remote: Total 117 (delta 0), reused 0 (delta 0), pack-reused 117\u001b[K\n",
      "Receiving objects: 100% (117/117), 198.73 KiB | 11.69 MiB/s, done.\n",
      "Resolving deltas: 100% (61/61), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hizhangp/yolo_tensorflow.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31489,
     "status": "ok",
     "timestamp": 1531793657749,
     "user": {
      "displayName": "Jiarong Ye",
      "photoUrl": "//lh4.googleusercontent.com/-q7b8noGUXEk/AAAAAAAAAAI/AAAAAAAAAPE/c6ZjOOV9LiQ/s50-c-k-no/photo.jpg",
      "userId": "110838105291424103468"
     },
     "user_tz": 240
    },
    "id": "EU7HKacz9j_f",
    "outputId": "da8cb814-665c-4153-9139-058383c3eaba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data directory...\r\n",
      "Downloading Pascal VOC 2012 data...\r\n",
      "--2018-07-17 02:13:48--  http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar [following]\n",
      "--2018-07-17 02:13:48--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 460032000 (439M) [application/octet-stream]\n",
      "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
      "\n",
      "VOCtrainval_06-Nov- 100%[===================>] 438.72M  44.2MB/s    in 15s     \n",
      "\n",
      "2018-07-17 02:14:03 (29.2 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
      "\n",
      "Extracting VOC data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!./yolo_tensorflow/download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 39
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32123,
     "status": "ok",
     "timestamp": 1531793689972,
     "user": {
      "displayName": "Jiarong Ye",
      "photoUrl": "//lh4.googleusercontent.com/-q7b8noGUXEk/AAAAAAAAAAI/AAAAAAAAAPE/c6ZjOOV9LiQ/s50-c-k-no/photo.jpg",
      "userId": "110838105291424103468"
     },
     "user_tz": 240
    },
    "id": "E5BexLAL-bNj",
    "outputId": "ffb28b4a-bae9-4bcd-926c-10f190bf3f08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8f8474ef-c627-4fdd-b00e-c573b42300bf\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8f8474ef-c627-4fdd-b00e-c573b42300bf\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4603,
     "status": "ok",
     "timestamp": 1531793694673,
     "user": {
      "displayName": "Jiarong Ye",
      "photoUrl": "//lh4.googleusercontent.com/-q7b8noGUXEk/AAAAAAAAAAI/AAAAAAAAAPE/c6ZjOOV9LiQ/s50-c-k-no/photo.jpg",
      "userId": "110838105291424103468"
     },
     "user_tz": 240
    },
    "id": "yDBExDIz9-Co",
    "outputId": "34ebd971-ed1d-4c15-ff50-a91ecf9221bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'YOLO_small.tar.gz': No such file or directory\n",
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir weights\n",
    "!mv YOLO_small.tar.gz ./weights\n",
    "!mkdir data\n",
    "!mv weights ./data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "357yCdVKE9-e"
   },
   "outputs": [],
   "source": [
    "ls data/weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "pdzn7Jfo_Dum",
    "outputId": "08e04556-6822-4796-c1fb-debf798fc759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/yolo_tensorflow/yolo/yolo_net.py:186: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Processing gt_labels from: data/pascal_voc/VOCdevkit/VOC2007\n",
      "Saving gt_labels to: data/pascal_voc/cache/pascal_train_gt_labels.pkl\n",
      "Appending horizontally-flipped training examples ...\n",
      "2018-07-17 02:15:22.433503: W tensorflow/core/framework/allocator.cc:108] Allocation of 24084480 exceeds 10% of system memory.\n",
      "2018-07-17 02:15:22.757500: W tensorflow/core/framework/allocator.cc:108] Allocation of 102760448 exceeds 10% of system memory.\n",
      "2018-07-17 02:15:22.767540: W tensorflow/core/framework/allocator.cc:108] Allocation of 18874368 exceeds 10% of system memory.\n",
      "2018-07-17 02:15:23.521142: W tensorflow/core/framework/allocator.cc:108] Allocation of 18874368 exceeds 10% of system memory.\n",
      "2018-07-17 02:15:23.672302: W tensorflow/core/framework/allocator.cc:108] Allocation of 37748736 exceeds 10% of system memory.\n",
      "Start training ...\n",
      "tcmalloc: large alloc 1327718400 bytes == 0x6d4a6000 @  0x7f39eb149107 0x7f39de34d575 0x7f39e04ddc19 0x7f39e04e823a 0x7f39e04e8a1d 0x7f39e0506d87 0x7f39e05071e9 0x7f39e0508525 0x7f39dc564c5c 0x7f39dc51c5fd 0x7f39dc50e2a5 0x7f39dc57b7c2 0x7f39dc579707 0x7f39e9a8c0ff 0x7f39eaefe7fc 0x7f39ea085b5f (nil)\n",
      "tcmalloc: large alloc 1301012480 bytes == 0xcf5a4000 @  0x7f39eb149107 0x7f39de34d575 0x7f39e04ddc19 0x7f39e04e823a 0x7f39e04e8a1d 0x7f39e0506d87 0x7f39e05071e9 0x7f39e0508525 0x7f39dc564c5c 0x7f39dc51c5fd 0x7f39dc50e2a5 0x7f39dc57b7c2 0x7f39dc579707 0x7f39e9a8c0ff 0x7f39eaefe7fc 0x7f39ea085b5f (nil)\n"
     ]
    }
   ],
   "source": [
    "!python yolo_tensorflow/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9j09Q7HL_GD0"
   },
   "outputs": [],
   "source": [
    "!python yolo_tensorflow/test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2A2S34D4p4E"
   },
   "source": [
    "## YOLONET 源码阅读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6v9Dmst47aq"
   },
   "source": [
    "与大部分目标检测与识别方法（比如Fast R-CNN）将目标识别任务分类多个流程不同:\n",
    "- 目标区域预测\n",
    "- 类别预测\n",
    "\n",
    "YOLO将目标区域预测和目标类别预测整合于__单个神经网络模型__中，实现在准确率较高的情况下快速目标检测与识别，更加适合现场应用环境。\n",
    "\n",
    "网络建立是通过build_networks()方法实现的，网络由卷积层-pooling层和全连接层组成\n",
    "\n",
    "__网络接受输入维度为([None, 448, 448, 3])，输出维度为([None,1470]__\n",
    "\n",
    "\n",
    "![](https://pic4.zhimg.com/80/v2-ee4db90336d60d251d7254f9918c3a48_hd.jpg)\n",
    "\n",
    "\n",
    "\n",
    "__loss函数代码的关键，loss函数定义为__\n",
    "\n",
    "![](https://pic3.zhimg.com/80/v2-99be5fd97cee75068fbbe82f8c381275_hd.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NSMXzwmK5W6H"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import yolo_tensorflow.yolo.config as cfg\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OxnfsAOm4pbl"
   },
   "outputs": [],
   "source": [
    "class YOLONet(object):\n",
    "\n",
    "    def __init__(self, is_training=True):\n",
    "        self.classes = cfg.CLASSES\n",
    "        self.num_class = len(self.classes) #类别数量，值为20\n",
    "        self.image_size = cfg.IMAGE_SIZE  #图像尺寸,值为448\n",
    "        self.cell_size = cfg.CELL_SIZE   #cell尺寸，值为7\n",
    "        self.boxes_per_cell = cfg.BOXES_PER_CELL #每个grid cell负责的boxes，默认为2\n",
    "        self.output_size = (self.cell_size * self.cell_size) *\\\n",
    "            (self.num_class + self.boxes_per_cell * 5)  #输出尺寸\n",
    "        self.scale = 1.0 * self.image_size / self.cell_size\n",
    "        self.boundary1 = self.cell_size * self.cell_size * self.num_class\n",
    "        self.boundary2 = self.boundary1 +\\\n",
    "            self.cell_size * self.cell_size * self.boxes_per_cell\n",
    "\n",
    "        self.object_scale = cfg.OBJECT_SCALE\n",
    "        self.noobject_scale = cfg.NOOBJECT_SCALE\n",
    "        self.class_scale = cfg.CLASS_SCALE\n",
    "        self.coord_scale = cfg.COORD_SCALE\n",
    "\n",
    "        self.learning_rate = cfg.LEARNING_RATE #学习速率LEARNING_RATE = 0.0001\n",
    "        self.batch_size = cfg.BATCH_SIZE\n",
    "        self.alpha = cfg.ALPHA\n",
    "\n",
    "        self.offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(self.cell_size)] * self.cell_size * self.boxes_per_cell),\n",
    "            (self.boxes_per_cell, self.cell_size, self.cell_size)), (1, 2, 0))\n",
    "\n",
    "        self.images = tf.placeholder(\n",
    "            tf.float32, [None, self.image_size, self.image_size, 3],\n",
    "            name='images')\n",
    "        self.logits = self.build_network(\n",
    "            self.images, num_outputs=self.output_size, alpha=self.alpha,\n",
    "            is_training=is_training)\n",
    "\n",
    "        if is_training:\n",
    "            self.labels = tf.placeholder(\n",
    "                tf.float32,\n",
    "                [None, self.cell_size, self.cell_size, 5 + self.num_class])\n",
    "            self.loss_layer(self.logits, self.labels)\n",
    "            self.total_loss = tf.losses.get_total_loss()\n",
    "            tf.summary.scalar('total_loss', self.total_loss)\n",
    "\n",
    "    def build_network(self,\n",
    "                      images,\n",
    "                      num_outputs,\n",
    "                      alpha,\n",
    "                      keep_prob=0.5,\n",
    "                      is_training=True,\n",
    "                      scope='yolo'):\n",
    "        with tf.variable_scope(scope):\n",
    "            with slim.arg_scope(\n",
    "                [slim.conv2d, slim.fully_connected],\n",
    "                activation_fn=leaky_relu(alpha),\n",
    "                weights_regularizer=slim.l2_regularizer(0.0005),\n",
    "                weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)\n",
    "            ):\n",
    "                net = tf.pad(\n",
    "                    images, np.array([[0, 0], [3, 3], [3, 3], [0, 0]]),\n",
    "                    name='pad_1')\n",
    "                net = slim.conv2d(\n",
    "                    net, 64, 7, 2, padding='VALID', scope='conv_2')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_3')\n",
    "                net = slim.conv2d(net, 192, 3, scope='conv_4')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_5')\n",
    "                net = slim.conv2d(net, 128, 1, scope='conv_6')\n",
    "                net = slim.conv2d(net, 256, 3, scope='conv_7')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_8')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_9')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_10')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_11')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_12')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_13')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_14')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_15')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_16')\n",
    "                net = slim.conv2d(net, 256, 1, scope='conv_17')\n",
    "                net = slim.conv2d(net, 512, 3, scope='conv_18')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_19')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_20')\n",
    "                net = slim.max_pool2d(net, 2, padding='SAME', scope='pool_21')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_22')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_23')\n",
    "                net = slim.conv2d(net, 512, 1, scope='conv_24')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_25')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_26')\n",
    "                net = tf.pad(\n",
    "                    net, np.array([[0, 0], [1, 1], [1, 1], [0, 0]]),\n",
    "                    name='pad_27')\n",
    "                net = slim.conv2d(\n",
    "                    net, 1024, 3, 2, padding='VALID', scope='conv_28')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_29')\n",
    "                net = slim.conv2d(net, 1024, 3, scope='conv_30')\n",
    "                net = tf.transpose(net, [0, 3, 1, 2], name='trans_31')\n",
    "                net = slim.flatten(net, scope='flat_32')\n",
    "                net = slim.fully_connected(net, 512, scope='fc_33')\n",
    "                net = slim.fully_connected(net, 4096, scope='fc_34')\n",
    "                net = slim.dropout(\n",
    "                    net, keep_prob=keep_prob, is_training=is_training,\n",
    "                    scope='dropout_35')\n",
    "                net = slim.fully_connected(\n",
    "                    net, num_outputs, activation_fn=None, scope='fc_36')\n",
    "        return net\n",
    "\n",
    "    def calc_iou(self, boxes1, boxes2, scope='iou'):\n",
    "        \"\"\"calculate ious\n",
    "        Args:\n",
    "          boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "          boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "        Return:\n",
    "          iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(scope):\n",
    "            # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "            boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                                 boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                                 boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                                 boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                                axis=-1)\n",
    "\n",
    "            boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                                 boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                                 boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                                axis=-1)\n",
    "\n",
    "            # calculate the left up point & right down point\n",
    "            lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "            rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "            # intersection\n",
    "            intersection = tf.maximum(0.0, rd - lu)\n",
    "            inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "            # calculate the boxs1 square and boxs2 square\n",
    "            square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "            square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "            union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "        return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
    "\n",
    "    def loss_layer(self, predicts, labels, scope='loss_layer'):\n",
    "        #将网络输出分离为类别和定位以及box大小，输出维度为7*7*20+7*7*2+7*7*2*4=1470\n",
    "        with tf.variable_scope(scope):\n",
    "            #类别，shape为(45, 7, 7, 20)\n",
    "            predict_classes = tf.reshape(\n",
    "                predicts[:, :self.boundary1],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.num_class])\n",
    "            #定位，shape为(45, 7, 7, 2)\n",
    "            predict_scales = tf.reshape(\n",
    "                predicts[:, self.boundary1:self.boundary2],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            ##box大小，长宽等 shape为(45, 7, 7, 2, 4)\n",
    "            predict_boxes = tf.reshape(\n",
    "                predicts[:, self.boundary2:],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, self.boxes_per_cell, 4])\n",
    "            #label的类别结果，shape为(45, 7, 7, 1)\n",
    "            response = tf.reshape(\n",
    "                labels[..., 0],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, 1])\n",
    "            #label的定位结果，shape为(45, 7, 7, 1, 4) => [x,y,w,h]\n",
    "            boxes = tf.reshape(\n",
    "                labels[..., 1:5],\n",
    "                [self.batch_size, self.cell_size, self.cell_size, 1, 4])\n",
    "            boxes = tf.tile(\n",
    "                boxes, [1, 1, 1, self.boxes_per_cell, 1]) / self.image_size\n",
    "            classes = labels[..., 5:]\n",
    "\n",
    "            offset = tf.reshape(\n",
    "                tf.constant(self.offset, dtype=tf.float32),\n",
    "                [1, self.cell_size, self.cell_size, self.boxes_per_cell])\n",
    "            offset = tf.tile(offset, [self.batch_size, 1, 1, 1])\n",
    "            offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "            predict_boxes_tran = tf.stack(\n",
    "                [(predict_boxes[..., 0] + offset) / self.cell_size,\n",
    "                 (predict_boxes[..., 1] + offset_tran) / self.cell_size,\n",
    "                 tf.square(predict_boxes[..., 2]),\n",
    "                 tf.square(predict_boxes[..., 3])], axis=-1)\n",
    "\n",
    "            iou_predict_truth = self.calc_iou(predict_boxes_tran, boxes)\n",
    "\n",
    "            # calculate I tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            object_mask = tf.reduce_max(iou_predict_truth, 3, keep_dims=True)\n",
    "            object_mask = tf.cast(\n",
    "                (iou_predict_truth >= object_mask), tf.float32) * response\n",
    "\n",
    "            # calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "            noobject_mask = tf.ones_like(\n",
    "                object_mask, dtype=tf.float32) - object_mask\n",
    "\n",
    "            boxes_tran = tf.stack(\n",
    "                [boxes[..., 0] * self.cell_size - offset,\n",
    "                 boxes[..., 1] * self.cell_size - offset_tran,\n",
    "                 tf.sqrt(boxes[..., 2]),\n",
    "                 tf.sqrt(boxes[..., 3])], axis=-1)\n",
    "\n",
    "            # class_loss\n",
    "            class_delta = response * (predict_classes - classes)\n",
    "            class_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(class_delta), axis=[1, 2, 3]),\n",
    "                name='class_loss') * self.class_scale\n",
    "\n",
    "            # object_loss\n",
    "            object_delta = object_mask * (predict_scales - iou_predict_truth)\n",
    "            object_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(object_delta), axis=[1, 2, 3]),\n",
    "                name='object_loss') * self.object_scale\n",
    "\n",
    "            # noobject_loss\n",
    "            noobject_delta = noobject_mask * predict_scales\n",
    "            noobject_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(noobject_delta), axis=[1, 2, 3]),\n",
    "                name='noobject_loss') * self.noobject_scale\n",
    "\n",
    "            # coord_loss\n",
    "            coord_mask = tf.expand_dims(object_mask, 4)\n",
    "            boxes_delta = coord_mask * (predict_boxes - boxes_tran)\n",
    "            coord_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(boxes_delta), axis=[1, 2, 3, 4]),\n",
    "                name='coord_loss') * self.coord_scale\n",
    "\n",
    "            tf.losses.add_loss(class_loss)\n",
    "            tf.losses.add_loss(object_loss)\n",
    "            tf.losses.add_loss(noobject_loss)\n",
    "            tf.losses.add_loss(coord_loss)\n",
    "\n",
    "            tf.summary.scalar('class_loss', class_loss)\n",
    "            tf.summary.scalar('object_loss', object_loss)\n",
    "            tf.summary.scalar('noobject_loss', noobject_loss)\n",
    "            tf.summary.scalar('coord_loss', coord_loss)\n",
    "\n",
    "            tf.summary.histogram('boxes_delta_x', boxes_delta[..., 0])\n",
    "            tf.summary.histogram('boxes_delta_y', boxes_delta[..., 1])\n",
    "            tf.summary.histogram('boxes_delta_w', boxes_delta[..., 2])\n",
    "            tf.summary.histogram('boxes_delta_h', boxes_delta[..., 3])\n",
    "            tf.summary.histogram('iou', iou_predict_truth)\n",
    "\n",
    "\n",
    "def leaky_relu(alpha):\n",
    "    def op(inputs):\n",
    "        return tf.nn.leaky_relu(inputs, alpha=alpha, name='leaky_relu')\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1J2aFnVDDzGy"
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zc5cG6eVDz9N"
   },
   "outputs": [],
   "source": [
    "class Solver(object):\n",
    "\n",
    "    def __init__(self, net, data):\n",
    "        self.net = net\n",
    "        self.data = data\n",
    "        self.weights_file = cfg.WEIGHTS_FILE\n",
    "        self.max_iter = cfg.MAX_ITER\n",
    "        self.initial_learning_rate = cfg.LEARNING_RATE\n",
    "        self.decay_steps = cfg.DECAY_STEPS  #速率延迟步数DECAY_STEPS = 30000\n",
    "        self.decay_rate = cfg.DECAY_RATE #延迟率DECAY_RATE = 0.1\n",
    "        self.staircase = cfg.STAIRCASE\n",
    "        self.summary_iter = cfg.SUMMARY_ITER \n",
    "        self.save_iter = cfg.SAVE_ITER\n",
    "        self.output_dir = os.path.join(\n",
    "            cfg.OUTPUT_DIR, datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "        self.save_cfg()\n",
    "\n",
    "        self.variable_to_restore = tf.global_variables()\n",
    "        self.saver = tf.train.Saver(self.variable_to_restore, max_to_keep=None)\n",
    "        self.ckpt_file = os.path.join(self.output_dir, 'yolo')\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.writer = tf.summary.FileWriter(self.output_dir, flush_secs=60)\n",
    "\n",
    "        self.global_step = tf.train.create_global_step()\n",
    "        self.learning_rate = tf.train.exponential_decay(\n",
    "            self.initial_learning_rate, self.global_step, self.decay_steps,\n",
    "            self.decay_rate, self.staircase, name='learning_rate')\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=self.learning_rate)\n",
    "        self.train_op = slim.learning.create_train_op(\n",
    "            self.net.total_loss, self.optimizer, global_step=self.global_step)\n",
    "\n",
    "        gpu_options = tf.GPUOptions()\n",
    "        config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if self.weights_file is not None:\n",
    "            print('Restoring weights from: ' + self.weights_file)\n",
    "            self.saver.restore(self.sess, self.weights_file)\n",
    "\n",
    "        self.writer.add_graph(self.sess.graph)\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        train_timer = Timer()\n",
    "        load_timer = Timer()\n",
    "\n",
    "        for step in range(1, self.max_iter + 1):\n",
    "\n",
    "            load_timer.tic()\n",
    "            images, labels = self.data.get()\n",
    "            load_timer.toc()\n",
    "            feed_dict = {self.net.images: images,\n",
    "                         self.net.labels: labels}\n",
    "\n",
    "            if step % self.summary_iter == 0:\n",
    "                if step % (self.summary_iter * 10) == 0:\n",
    "\n",
    "                    train_timer.tic()\n",
    "                    summary_str, loss, _ = self.sess.run(\n",
    "                        [self.summary_op, self.net.total_loss, self.train_op],\n",
    "                        feed_dict=feed_dict)\n",
    "                    train_timer.toc()\n",
    "\n",
    "                    log_str = '''{} Epoch: {}, Step: {}, Learning rate: {},'''\n",
    "                    ''' Loss: {:5.3f}\\nSpeed: {:.3f}s/iter,'''\n",
    "                    '''' Load: {:.3f}s/iter, Remain: {}'''.format(\n",
    "                        datetime.datetime.now().strftime('%m-%d %H:%M:%S'),\n",
    "                        self.data.epoch,\n",
    "                        int(step),\n",
    "                        round(self.learning_rate.eval(session=self.sess), 6),\n",
    "                        loss,\n",
    "                        train_timer.average_time,\n",
    "                        load_timer.average_time,\n",
    "                        train_timer.remain(step, self.max_iter))\n",
    "                    print(log_str)\n",
    "\n",
    "                else:\n",
    "                    train_timer.tic()\n",
    "                    summary_str, _ = self.sess.run(\n",
    "                        [self.summary_op, self.train_op],\n",
    "                        feed_dict=feed_dict)\n",
    "                    train_timer.toc()\n",
    "\n",
    "                self.writer.add_summary(summary_str, step)\n",
    "\n",
    "            else:\n",
    "                train_timer.tic()\n",
    "                self.sess.run(self.train_op, feed_dict=feed_dict)\n",
    "                train_timer.toc()\n",
    "\n",
    "            if step % self.save_iter == 0:\n",
    "                print('{} Saving checkpoint file to: {}'.format(\n",
    "                    datetime.datetime.now().strftime('%m-%d %H:%M:%S'),\n",
    "                    self.output_dir))\n",
    "                self.saver.save(\n",
    "                    self.sess, self.ckpt_file, global_step=self.global_step)\n",
    "\n",
    "    def save_cfg(self):\n",
    "\n",
    "        with open(os.path.join(self.output_dir, 'config.txt'), 'w') as f:\n",
    "            cfg_dict = cfg.__dict__\n",
    "            for key in sorted(cfg_dict.keys()):\n",
    "                if key[0].isupper():\n",
    "                    cfg_str = '{}: {}\\n'.format(key, cfg_dict[key])\n",
    "                    f.write(cfg_str)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "l2A2S34D4p4E"
   ],
   "default_view": {},
   "name": "Another YOLO in tensorflow.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
