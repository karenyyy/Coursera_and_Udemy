{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@3bbf0b8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Column\n",
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "import sqlContext.implicits._\n",
    "val spark = SparkSession.builder().appName(\"Spark Example\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+\n",
      "| Id|MSSubClass|SalePrice|\n",
      "+---+----------+---------+\n",
      "|  1|        60|   208500|\n",
      "|  2|        20|   181500|\n",
      "|  3|        60|   223500|\n",
      "|  4|        70|   140000|\n",
      "|  5|        60|   250000|\n",
      "|  6|        50|   143000|\n",
      "|  7|        20|   307000|\n",
      "|  8|        60|   200000|\n",
      "|  9|        50|   129900|\n",
      "| 10|       190|   118000|\n",
      "| 11|        20|   129500|\n",
      "| 12|        60|   345000|\n",
      "| 13|        20|   144000|\n",
      "| 14|        20|   279500|\n",
      "| 15|        20|   157000|\n",
      "| 16|        45|   132000|\n",
      "| 17|        20|   149000|\n",
      "| 18|        90|    90000|\n",
      "| 19|        20|   159000|\n",
      "| 20|        20|   139000|\n",
      "+---+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", true).option(\"inferSchema\", true).csv(\"../data/train.csv\")\n",
    "df.select(\"Id\", \"MSSubClass\", \"SalePrice\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((Id,IntegerType), (MSSubClass,IntegerType), (MSZoning,StringType), (LotFrontage,StringType), (LotArea,IntegerType), (Street,StringType), (Alley,StringType), (LotShape,StringType), (LandContour,StringType), (Utilities,StringType), (LotConfig,StringType), (LandSlope,StringType), (Neighborhood,StringType), (Condition1,StringType), (Condition2,StringType), (BldgType,StringType), (HouseStyle,StringType), (OverallQual,IntegerType), (OverallCond,IntegerType), (YearBuilt,IntegerType), (YearRemodAdd,IntegerType), (RoofStyle,StringType), (RoofMatl,StringType), (Exterior1st,StringType), (Exterior2nd,StringType), (MasVnrType,StringType), (MasVnrArea,StringType), (ExterQual,StringType), (ExterCond,StringType), (Foundation,StringType), (BsmtQual,StringType), (Bsm..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| Id|SalePrice|\n",
      "+---+---------+\n",
      "|  1|   208500|\n",
      "|  3|   223500|\n",
      "|  5|   250000|\n",
      "|  7|   307000|\n",
      "| 12|   345000|\n",
      "| 14|   279500|\n",
      "| 21|   325300|\n",
      "| 23|   230000|\n",
      "| 26|   256300|\n",
      "| 28|   306000|\n",
      "| 29|   207500|\n",
      "| 35|   277500|\n",
      "| 36|   309000|\n",
      "| 46|   319900|\n",
      "| 47|   239686|\n",
      "| 48|   249700|\n",
      "| 54|   385000|\n",
      "| 59|   438780|\n",
      "| 63|   202500|\n",
      "| 65|   219500|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df(\"SalePrice\")>200000).select(\"Id\", \"SalePrice\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.vegas-viz:vegas_2.11:0.3.8 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree_add_deps9214017498035841310/\n",
      "-> https://repo1.maven.org/maven2\n",
      "=> 1 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas_2.11/0.3.8/vegas_2.11-0.3.8.pom.sha1\n",
      "=> 2 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas_2.11/0.3.8/vegas_2.11-0.3.8.pom\n",
      "=> 1 (vegas_2.11-0.3.8.pom.sha1): Finished downloading\n",
      "=> 2 (vegas_2.11-0.3.8.pom): Finished downloading\n",
      "=> 3 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-macro_2.11/1.1.0/monocle-macro_2.11-1.1.0.pom\n",
      "=> 4 (): Downloading https://repo1.maven.org/maven2/org/scalafx/scalafx_2.11/8.0.92-R10/scalafx_2.11-8.0.92-R10.pom.sha1\n",
      "=> 5 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega-lite/1.2.0/vega-lite-1.2.0.pom.sha1\n",
      "=> 6 (): Downloading https://repo1.maven.org/maven2/org/scalafx/scalafx_2.11/8.0.92-R10/scalafx_2.11-8.0.92-R10.pom\n",
      "=> 7 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega-lite/1.2.0/vega-lite-1.2.0.pom\n",
      "=> 8 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-macro_2.11/1.1.0/monocle-macro_2.11-1.1.0.pom.sha1\n",
      "=> 3 (monocle-macro_2.11-1.1.0.pom): Finished downloading\n",
      "=> 9 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-core_2.11/1.1.0/monocle-core_2.11-1.1.0.pom\n",
      "=> 9 (monocle-core_2.11-1.1.0.pom): Finished downloading\n",
      "=> 10 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-core_2.11/1.1.0/monocle-core_2.11-1.1.0.pom.sha1\n",
      "=> 5 (vega-lite-1.2.0.pom.sha1): Finished downloading\n",
      "=> 11 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-core_2.11/0.4.1/circe-core_2.11-0.4.1.pom\n",
      "=> 6 (scalafx_2.11-8.0.92-R10.pom): Finished downloading\n",
      "=> 12 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-core_2.11/0.4.1/circe-core_2.11-0.4.1.pom.sha1\n",
      "=> 4 (scalafx_2.11-8.0.92-R10.pom.sha1): Finished downloading\n",
      "=> 13 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas-macros_2.11/0.3.8/vegas-macros_2.11-0.3.8.pom\n",
      "=> 8 (monocle-macro_2.11-1.1.0.pom.sha1): Finished downloading\n",
      "=> 14 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas-macros_2.11/0.3.8/vegas-macros_2.11-0.3.8.pom.sha1\n",
      "=> 7 (vega-lite-1.2.0.pom): Finished downloading\n",
      "=> 15 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-parser_2.11/0.4.1/circe-parser_2.11-0.4.1.pom\n",
      "=> 10 (monocle-core_2.11-1.1.0.pom.sha1): Finished downloading\n",
      "=> 16 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-parser_2.11/0.4.1/circe-parser_2.11-0.4.1.pom.sha1\n",
      "=> 11 (circe-core_2.11-0.4.1.pom): Finished downloading\n",
      "=> 12 (circe-core_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 17 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-generic_2.11/0.4.1/circe-generic_2.11-0.4.1.pom\n",
      "=> 18 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-generic_2.11/0.4.1/circe-generic_2.11-0.4.1.pom.sha1\n",
      "=> 13 (vegas-macros_2.11-0.3.8.pom): Finished downloading\n",
      "=> 15 (circe-parser_2.11-0.4.1.pom): Finished downloading\n",
      "=> 14 (vegas-macros_2.11-0.3.8.pom.sha1): Finished downloading\n",
      "=> 16 (circe-parser_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 18 (circe-generic_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 17 (circe-generic_2.11-0.4.1.pom): Finished downloading\n",
      "=> 19 (): Downloading https://repo1.maven.org/maven2/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.pom\n",
      "=> 20 (): Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.1.1/scalaz-core_2.11-7.1.1.pom\n",
      "=> 21 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-numbers_2.11/0.4.1/circe-numbers_2.11-0.4.1.pom\n",
      "=> 22 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-numbers_2.11/0.4.1/circe-numbers_2.11-0.4.1.pom.sha1\n",
      "=> 23 (): Downloading https://repo1.maven.org/maven2/org/typelevel/macro-compat_2.11/1.1.1/macro-compat_2.11-1.1.1.pom.sha1\n",
      "=> 24 (): Downloading https://repo1.maven.org/maven2/org/scalaz/scalaz-core_2.11/7.1.1/scalaz-core_2.11-7.1.1.pom.sha1\n",
      "=> 19 (macro-compat_2.11-1.1.1.pom): Finished downloading\n",
      "=> 22 (circe-numbers_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 25 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-jawn_2.11/0.4.1/circe-jawn_2.11-0.4.1.pom.sha1\n",
      "=> 21 (circe-numbers_2.11-0.4.1.pom): Finished downloading\n",
      "=> 26 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-jawn_2.11/0.4.1/circe-jawn_2.11-0.4.1.pom\n",
      "=> 27 (): Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/0.4.1/cats-core_2.11-0.4.1.pom\n",
      "=> 20 (scalaz-core_2.11-7.1.1.pom): Finished downloading\n",
      "=> 28 (): Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/0.4.1/cats-core_2.11-0.4.1.pom.sha1\n",
      "=> 23 (macro-compat_2.11-1.1.1.pom.sha1): Finished downloading\n",
      "=> 29 (): Downloading https://repo1.maven.org/maven2/com/chuusai/shapeless_2.11/2.3.0/shapeless_2.11-2.3.0.pom\n",
      "=> 25 (circe-jawn_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 30 (): Downloading https://repo1.maven.org/maven2/com/chuusai/shapeless_2.11/2.3.0/shapeless_2.11-2.3.0.pom.sha1\n",
      "=> 26 (circe-jawn_2.11-0.4.1.pom): Finished downloading\n",
      "=> 31 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega/maven-metadata.xml\n",
      "=> 29 (shapeless_2.11-2.3.0.pom): Finished downloading\n",
      "=> 32 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega/maven-metadata.xml.sha1\n",
      "=> 27 (cats-core_2.11-0.4.1.pom): Finished downloading\n",
      "=> 28 (cats-core_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 24 (scalaz-core_2.11-7.1.1.pom.sha1): Finished downloading\n",
      "=> 32 (maven-metadata.xml.sha1): Finished downloading\n",
      "=> 31 (maven-metadata.xml): Finished downloading\n",
      "=> 30 (shapeless_2.11-2.3.0.pom.sha1): Finished downloading\n",
      "=> 33 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega/3.0.0-rc4/vega-3.0.0-rc4.pom.sha1\n",
      "=> 34 (): Downloading https://repo1.maven.org/maven2/org/webjars/bower/vega/3.0.0-rc4/vega-3.0.0-rc4.pom\n",
      "=> 33 (vega-3.0.0-rc4.pom.sha1): Finished downloading\n",
      "=> 34 (vega-3.0.0-rc4.pom): Finished downloading\n",
      "=> 35 (): Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/0.4.1/cats-macros_2.11-0.4.1.pom\n",
      "=> 36 (): Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.4.1/machinist_2.11-0.4.1.pom\n",
      "=> 37 (): Downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.pom.sha1\n",
      "=> 38 (): Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.4.1/machinist_2.11-0.4.1.pom.sha1\n",
      "=> 39 (): Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/0.4.1/cats-macros_2.11-0.4.1.pom.sha1\n",
      "=> 40 (): Downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.pom\n",
      "=> 35 (cats-macros_2.11-0.4.1.pom): Finished downloading\n",
      "=> 36 (machinist_2.11-0.4.1.pom): Finished downloading\n",
      "=> 41 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra-std_2.11/0.3.1/algebra-std_2.11-0.3.1.pom\n",
      "=> 42 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra-std_2.11/0.3.1/algebra-std_2.11-0.3.1.pom.sha1\n",
      "=> 37 (scala-xml_2.11-1.0.2.pom.sha1): Finished downloading\n",
      "=> 43 (): Downloading https://repo1.maven.org/maven2/com/github/mpilquist/simulacrum_2.11/0.7.0/simulacrum_2.11-0.7.0.pom\n",
      "=> 38 (machinist_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 44 (): Downloading https://repo1.maven.org/maven2/com/github/mpilquist/simulacrum_2.11/0.7.0/simulacrum_2.11-0.7.0.pom.sha1\n",
      "=> 39 (cats-macros_2.11-0.4.1.pom.sha1): Finished downloading\n",
      "=> 45 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra_2.11/0.3.1/algebra_2.11-0.3.1.pom\n",
      "=> 41 (algebra-std_2.11-0.3.1.pom): Finished downloading\n",
      "=> 46 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra_2.11/0.3.1/algebra_2.11-0.3.1.pom.sha1\n",
      "=> 44 (simulacrum_2.11-0.7.0.pom.sha1): Finished downloading\n",
      "=> 43 (simulacrum_2.11-0.7.0.pom): Finished downloading\n",
      "=> 47 (): Downloading https://repo1.maven.org/maven2/org/spire-math/jawn-parser_2.11/0.8.4/jawn-parser_2.11-0.8.4.pom\n",
      "=> 48 (): Downloading https://repo1.maven.org/maven2/org/spire-math/jawn-parser_2.11/0.8.4/jawn-parser_2.11-0.8.4.pom.sha1\n",
      "=> 42 (algebra-std_2.11-0.3.1.pom.sha1): Finished downloading\n",
      "=> 49 (): Downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.pom\n",
      "=> 45 (algebra_2.11-0.3.1.pom): Finished downloading\n",
      "=> 50 (): Downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.pom.sha1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 40 (scala-xml_2.11-1.0.2.pom): Finished downloading\n",
      "=> 46 (algebra_2.11-0.3.1.pom.sha1): Finished downloading\n",
      "=> 48 (jawn-parser_2.11-0.8.4.pom.sha1): Finished downloading\n",
      "=> 47 (jawn-parser_2.11-0.8.4.pom): Finished downloading\n",
      "=> 50 (scala-parser-combinators_2.11-1.0.2.pom.sha1): Finished downloading\n",
      "=> 49 (scala-parser-combinators_2.11-1.0.2.pom): Finished downloading\n",
      "=> 1 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas-macros_2.11/0.3.8/vegas-macros_2.11-0.3.8.jar.sha1\n",
      "=> 2 (): Downloading https://repo1.maven.org/maven2/org/vegas-viz/vegas-macros_2.11/0.3.8/vegas-macros_2.11-0.3.8.jar\n",
      "=> 1 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra_2.11/0.3.1/algebra_2.11-0.3.1.jar\n",
      "=> 2 (): Downloading https://repo1.maven.org/maven2/org/spire-math/algebra_2.11/0.3.1/algebra_2.11-0.3.1.jar.sha1\n",
      "=> 1 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-core_2.11/1.1.0/monocle-core_2.11-1.1.0.jar.sha1\n",
      "=> 2 (): Downloading https://repo1.maven.org/maven2/com/github/julien-truffaut/monocle-core_2.11/1.1.0/monocle-core_2.11-1.1.0.jar\n",
      "=> 1 (vegas-macros_2.11-0.3.8.jar.sha1): Finished downloading\n",
      "=> 1 (): Downloading https://repo1.maven.org/maven2/io/circe/circe-numbers_2.11/0.4.1/circe-numbers_2.11-0.4.1.jar\n",
      "=> 1 (monocle-core_2.11-1.1.0.jar.sha1): Finished downloading\n",
      "=> 1 (): Do"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10283 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%AddDeps org.vegas-viz vegas_2.11 0.3.8 --transitive --verbose\n",
    "implicit val render = vegas.render.ShowHTML(kernel.display.content(\"text/html\", _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val yearly_salesprice = df.groupBy(\"YearBuilt\").agg(avg(\"SalePrice\")).sort(\"YearBuilt\")\n",
    "//yearly_salesprice.show()\n",
    "Vegas(\"Graph 1\").withData(yearly_salesprice.map(x => Map(\"YearBuilt\" -> x(0), \"SalePrice\" -> x(1)))).encodeX(\"YearBuilt\", Nom).encodeY(\"SalePrice\", Quant).mark(Bar).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-------------------+\n",
      "| Id|Sale Price in Dollars|Sale Price in Euros|\n",
      "+---+---------------------+-------------------+\n",
      "|  1|               208500|           187650.0|\n",
      "|  2|               181500|           163350.0|\n",
      "|  3|               223500|           201150.0|\n",
      "|  4|               140000|           126000.0|\n",
      "|  5|               250000|           225000.0|\n",
      "|  6|               143000|           128700.0|\n",
      "|  7|               307000|           276300.0|\n",
      "|  8|               200000|           180000.0|\n",
      "|  9|               129900|           116910.0|\n",
      "| 10|               118000|           106200.0|\n",
      "| 11|               129500|           116550.0|\n",
      "| 12|               345000|           310500.0|\n",
      "| 13|               144000|           129600.0|\n",
      "| 14|               279500|           251550.0|\n",
      "| 15|               157000|           141300.0|\n",
      "| 16|               132000|           118800.0|\n",
      "| 17|               149000|           134100.0|\n",
      "| 18|                90000|            81000.0|\n",
      "| 19|               159000|           143100.0|\n",
      "| 20|               139000|           125100.0|\n",
      "+---+---------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.sql.AnalysisException\n",
       "Message: path file:/home/karen/workspace/Coursera_and_Udemy/Big_Data_coursera/Exercises/notebooks/mydata.csv already exists.;\n",
       "StackTrace:   at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:106)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:435)\n",
       "  at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:471)\n",
       "  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:50)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n",
       "  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n",
       "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n",
       "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n",
       "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n",
       "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:609)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:233)\n",
       "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:217)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def dollarToEuros(c: Column):Column=c*0.9\n",
    "val dollars_and_euros = df.select($\"Id\", $\"SalePrice\" as \"Sale Price in Dollars\", dollarToEuros($\"SalePrice\") as \"Sale Price in Euros\")\n",
    "dollars_and_euros.show()\n",
    "dollars_and_euros.repartition(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"mydata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| Id|SalePrice|\n",
      "+---+---------+\n",
      "|  4|   140000|\n",
      "|  5|   250000|\n",
      "|  7|   307000|\n",
      "| 13|   144000|\n",
      "| 15|   157000|\n",
      "| 16|   132000|\n",
      "| 19|   159000|\n",
      "| 20|   139000|\n",
      "| 23|   230000|\n",
      "| 27|   134800|\n",
      "| 28|   306000|\n",
      "| 29|   207500|\n",
      "| 30|    68500|\n",
      "| 32|   149350|\n",
      "| 33|   179900|\n",
      "| 36|   309000|\n",
      "| 37|   145000|\n",
      "| 38|   153000|\n",
      "| 39|   109000|\n",
      "| 40|    82000|\n",
      "+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Random\", rand(2018)>0.5).filter(\"Random\").select(\"Id\",\"SalePrice\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------+\n",
      "|           Variance|              Mean|           Stddev|\n",
      "+-------------------+------------------+-----------------+\n",
      "|6.311111264297452E9|180921.19589041095|79442.50288288663|\n",
      "+-------------------+------------------+-----------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|         SalePrice|\n",
      "+-------+------------------+\n",
      "|  count|              1460|\n",
      "|   mean|180921.19589041095|\n",
      "| stddev| 79442.50288288663|\n",
      "|    min|             34900|\n",
      "|    max|            755000|\n",
      "+-------+------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|corr(OverallQual, SalePrice)|\n",
      "+----------------------------+\n",
      "|          0.7909816005838053|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val stat_basic = df.select(variance(\"SalePrice\") as \"Variance\",\n",
    "          mean(\"SalePrice\") as \"Mean\",\n",
    "          stddev(\"SalePrice\") as \"Stddev\")\n",
    "stat_basic.show()\n",
    "\n",
    "df.describe(\"SalePrice\").show\n",
    "df.select(corr(\"OverallQual\", \"SalePrice\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: java.lang.IllegalArgumentException\n",
       "Message: requirement failed: Column features must be of type org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7 but was actually org.apache.spark.mllib.linalg.VectorUDT@f71b0bce.\n",
       "StackTrace:   at scala.Predef$.require(Predef.scala:224)\n",
       "  at org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:42)\n",
       "  at org.apache.spark.ml.feature.StandardScalerParams$class.validateAndTransformSchema(StandardScaler.scala:67)\n",
       "  at org.apache.spark.ml.feature.StandardScaler.validateAndTransformSchema(StandardScaler.scala:87)\n",
       "  at org.apache.spark.ml.feature.StandardScaler.transformSchema(StandardScaler.scala:123)\n",
       "  at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n",
       "  at org.apache.spark.ml.feature.StandardScaler.fit(StandardScaler.scala:112)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StandardScaler\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "val data = MLUtils.loadLibSVMFile(sc, \"../data/sample_libsvm_data.txt\")\n",
    "val dataFrame = sqlContext.createDataFrame(data)\n",
    "//dataFrame.show\n",
    "val scaler = new StandardScaler().setInputCol(\"features\").setOutputCol(\"scaledFeatures\").setWithStd(true).setWithMean(false)\n",
    "\n",
    "val scalerModel = scaler.fit(dataFrame)\n",
    "\n",
    "// val scaledData = scalerModel.transform(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> how does ___*__ works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:36: error: type mismatch;\n",
       " found   : Array[String]\n",
       " required: String\n",
       "       echo(arr)\n",
       "            ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def echo(args: String*) = for (arg <- args) println(arg)\n",
    "val arr = Array(\"What's\", \"up\", \"doc?\")\n",
    "echo(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's\n",
      "up\n",
      "doc?\n"
     ]
    }
   ],
   "source": [
    "echo(arr:_*) // here, ':Type' is basically like the Type Cast in C++ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "MSSubClass\n",
      "LotArea\n",
      "OverallQual\n",
      "OverallCond\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "BsmtFinSF1\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "1stFlrSF\n",
      "2ndFlrSF\n",
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "FullBath\n",
      "HalfBath\n",
      "BedroomAbvGr\n",
      "KitchenAbvGr\n",
      "TotRmsAbvGrd\n",
      "Fireplaces\n",
      "GarageCars\n",
      "GarageArea\n",
      "WoodDeckSF\n",
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n",
      "MiscVal\n",
      "MoSold\n",
      "YrSold\n",
      "SalePrice\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructField, IntegerType}\n",
    "val fields = df.schema.fields.collect{ case StructField(name, IntegerType, _, _)=> name }\n",
    "fields.foreach(println(_))\n",
    "val correlations = df.select(fields.map(corr(_, \"SalePrice\")):_*).first.toSeq\n",
    "//correlations.foreach(println)\n",
    "val dict = fields zip correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Id,-0.021916719443430967)\n",
      "(MSSubClass,-0.08428413512659509)\n",
      "(LotArea,0.2638433538714051)\n",
      "(OverallQual,0.7909816005838053)\n",
      "(OverallCond,-0.07785589404867797)\n",
      "(YearBuilt,0.5228973328794967)\n",
      "(YearRemodAdd,0.5071009671113866)\n",
      "(BsmtFinSF1,0.38641980624215344)\n",
      "(BsmtFinSF2,-0.01137812145021515)\n",
      "(BsmtUnfSF,0.21447910554696928)\n",
      "(TotalBsmtSF,0.6135805515591943)\n",
      "(1stFlrSF,0.6058521846919153)\n",
      "(2ndFlrSF,0.31933380283206736)\n",
      "(LowQualFinSF,-0.02560613000067955)\n",
      "(GrLivArea,0.7086244776126515)\n",
      "(BsmtFullBath,0.22712223313149427)\n",
      "(BsmtHalfBath,-0.016844154297358943)\n",
      "(FullBath,0.5606637627484453)\n",
      "(HalfBath,0.28410767559478256)\n",
      "(BedroomAbvGr,0.16821315430073963)\n",
      "(KitchenAbvGr,-0.13590737084214105)\n",
      "(TotRmsAbvGrd,0.5337231555820284)\n",
      "(Fireplaces,0.46692883675152763)\n",
      "(GarageCars,0.6404091972583519)\n",
      "(GarageArea,0.6234314389183622)\n",
      "(WoodDeckSF,0.32441344456812926)\n",
      "(OpenPorchSF,0.31585622711605504)\n",
      "(EnclosedPorch,-0.1285779579259566)\n",
      "(3SsnPorch,0.04458366533574838)\n",
      "(ScreenPorch,0.11144657114291112)\n",
      "(PoolArea,0.09240354949187318)\n",
      "(MiscVal,-0.021189579640303213)\n",
      "(MoSold,0.046432245223819446)\n",
      "(YrSold,-0.028922585168736813)\n",
      "(SalePrice,1.0)\n"
     ]
    }
   ],
   "source": [
    "dict.foreach(println(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing using mllib package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Id: int, MSSubClass: int ... 79 more fields]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SparkSession, Column}\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"ML Example\").getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "val df = spark.read.option(\"header\", true).option(\"inferSchema\", true).csv(\"../data/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Data Transformations and Creating Scalar features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|labels|\n",
      "+--------------------+------+\n",
      "|[60.0,8450.0,7.0,...|208500|\n",
      "|[20.0,9600.0,6.0,...|181500|\n",
      "|[60.0,11250.0,7.0...|223500|\n",
      "|[70.0,9550.0,7.0,...|140000|\n",
      "|[60.0,14260.0,8.0...|250000|\n",
      "|[50.0,14115.0,5.0...|143000|\n",
      "|[20.0,10084.0,8.0...|307000|\n",
      "|[60.0,10382.0,7.0...|200000|\n",
      "|[50.0,6120.0,7.0,...|129900|\n",
      "|[190.0,7420.0,5.0...|118000|\n",
      "|[20.0,11200.0,5.0...|129500|\n",
      "|[60.0,11924.0,9.0...|345000|\n",
      "|[20.0,12968.0,5.0...|144000|\n",
      "|[20.0,10652.0,7.0...|279500|\n",
      "|[20.0,10920.0,6.0...|157000|\n",
      "|[45.0,6120.0,7.0,...|132000|\n",
      "|[20.0,11241.0,6.0...|149000|\n",
      "|[90.0,10791.0,4.0...| 90000|\n",
      "|[20.0,13695.0,5.0...|159000|\n",
      "|[20.0,7560.0,5.0,...|139000|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.sql.types.{StructField, IntegerType, StringType}\n",
    "\n",
    "val labelField = \"SalePrice\"\n",
    "val scalarFields:Seq[String] = df.schema.fields.collect{ case StructField(name,IntegerType, _, _)\n",
    "                                                       if name!=labelField && name !=\"Id\" => name}\n",
    "val scalarData = df.map{row=>(\n",
    "    Vectors.dense(scalarFields.map(name=>row.getAs[Int](name).toDouble).toArray),\n",
    "    row.getInt(row.fieldIndex(labelField)))\n",
    "                       }.toDF(\"features\", \"labels\") // here labels is SalesPrice, use all other variables to predict SalesPrice\n",
    "scalarData.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       avg(labels)|\n",
      "+------------------+\n",
      "|180921.19589041095|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val mean_features = scalarData.select(mean(scalarData(\"labels\")))\n",
    "mean_features.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feature Transformers\n",
    "#### Categorical features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> how does __foldLeft__ works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val listA = List(1,2,3)\n",
    "val cum = listA.foldLeft(0)((sum, i)=>sum+i)\n",
    "cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "LotFrontage\n",
      "Street\n",
      "Alley\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "MasVnrArea\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n",
      "SaleType\n",
      "SaleCondition\n",
      "+--------+-----------+\n",
      "|MSZoning|MSZoning_id|\n",
      "+--------+-----------+\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RM|        1.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RM|        1.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "|      RL|        0.0|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val stringFields: Seq[String] = df.schema.fields.collect{case StructField(name, StringType, _, _) => name}\n",
    "\n",
    "val dfWithCategories = stringFields.foldLeft(df){ (dfTemp, col) => \n",
    "    val indexer = new StringIndexer().setInputCol(col).setOutputCol(s\"${col}_id\")\n",
    "    indexer.fit(dfTemp).transform(dfTemp)\n",
    "    }\n",
    "stringFields.foreach(println)\n",
    "dfWithCategories.select(\"MSZoning\", \"MSZoning_id\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|      feature_scaler| feature_categorical| label|\n",
      "+--------------------+--------------------+------+\n",
      "|[60.0,8450.0,7.0,...|[0.0,6.0,0.0,0.0,...|208500|\n",
      "|[20.0,9600.0,6.0,...|[0.0,3.0,0.0,0.0,...|181500|\n",
      "|[60.0,11250.0,7.0...|[0.0,11.0,0.0,0.0...|223500|\n",
      "|[70.0,9550.0,7.0,...|[0.0,1.0,0.0,0.0,...|140000|\n",
      "|[60.0,14260.0,8.0...|[0.0,38.0,0.0,0.0...|250000|\n",
      "|[50.0,14115.0,5.0...|[0.0,7.0,0.0,0.0,...|143000|\n",
      "|[20.0,10084.0,8.0...|[0.0,5.0,0.0,0.0,...|307000|\n",
      "|[60.0,10382.0,7.0...|[0.0,0.0,0.0,0.0,...|200000|\n",
      "|[50.0,6120.0,7.0,...|[1.0,21.0,0.0,0.0...|129900|\n",
      "|[190.0,7420.0,5.0...|[0.0,4.0,0.0,0.0,...|118000|\n",
      "|[20.0,11200.0,5.0...|[0.0,2.0,0.0,0.0,...|129500|\n",
      "|[60.0,11924.0,9.0...|[0.0,7.0,0.0,0.0,...|345000|\n",
      "|[20.0,12968.0,5.0...|[0.0,0.0,0.0,0.0,...|144000|\n",
      "|[20.0,10652.0,7.0...|[0.0,61.0,0.0,0.0...|279500|\n",
      "|[20.0,10920.0,6.0...|[0.0,0.0,0.0,0.0,...|157000|\n",
      "|[45.0,6120.0,7.0,...|[1.0,21.0,0.0,0.0...|132000|\n",
      "|[20.0,11241.0,6.0...|[0.0,0.0,0.0,0.0,...|149000|\n",
      "|[90.0,10791.0,4.0...|[0.0,17.0,0.0,0.0...| 90000|\n",
      "|[20.0,13695.0,5.0...|[0.0,20.0,0.0,0.0...|159000|\n",
      "|[20.0,7560.0,5.0,...|[0.0,2.0,0.0,0.0,...|139000|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val data = dfWithCategories.map{row=>\n",
    "        (\n",
    "        Vectors.dense(scalarFields.map(name=>row.getAs[Int](name).toDouble).toArray),\n",
    "        Vectors.dense(stringFields.map(name=>row.getAs[Double](s\"${name}_id\")).toArray),\n",
    "        row.getInt(row.fieldIndex(labelField))\n",
    "        )\n",
    "    }.toDF(\"feature_scaler\", \"feature_categorical\", \"label\")\n",
    "\n",
    "// val temp = data.rdd.zipWithIndex().filter{ case (row,index)=>index==100}.map{ case(row, index)=> \n",
    "//     (index, row)}\n",
    "// val val_0 = temp.mapValues(x=>x(1)).collect\n",
    "// val_0\n",
    "data.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Scaling scalar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+---------------------+\n",
      "|      feature_scaler| feature_categorical| label|feature_scaler_scaled|\n",
      "+--------------------+--------------------+------+---------------------+\n",
      "|[60.0,8450.0,7.0,...|[0.0,6.0,0.0,0.0,...|208500| [0.07334983082099...|\n",
      "|[20.0,9600.0,6.0,...|[0.0,3.0,0.0,0.0,...|181500| [-0.8722638821913...|\n",
      "|[60.0,11250.0,7.0...|[0.0,11.0,0.0,0.0...|223500| [0.07334983082099...|\n",
      "|[70.0,9550.0,7.0,...|[0.0,1.0,0.0,0.0,...|140000| [0.30975325907408...|\n",
      "|[60.0,14260.0,8.0...|[0.0,38.0,0.0,0.0...|250000| [0.07334983082099...|\n",
      "|[50.0,14115.0,5.0...|[0.0,7.0,0.0,0.0,...|143000| [-0.1630535974320...|\n",
      "|[20.0,10084.0,8.0...|[0.0,5.0,0.0,0.0,...|307000| [-0.8722638821913...|\n",
      "|[60.0,10382.0,7.0...|[0.0,0.0,0.0,0.0,...|200000| [0.07334983082099...|\n",
      "|[50.0,6120.0,7.0,...|[1.0,21.0,0.0,0.0...|129900| [-0.1630535974320...|\n",
      "|[190.0,7420.0,5.0...|[0.0,4.0,0.0,0.0,...|118000| [3.14659439811116...|\n",
      "|[20.0,11200.0,5.0...|[0.0,2.0,0.0,0.0,...|129500| [-0.8722638821913...|\n",
      "|[60.0,11924.0,9.0...|[0.0,7.0,0.0,0.0,...|345000| [0.07334983082099...|\n",
      "|[20.0,12968.0,5.0...|[0.0,0.0,0.0,0.0,...|144000| [-0.8722638821913...|\n",
      "|[20.0,10652.0,7.0...|[0.0,61.0,0.0,0.0...|279500| [-0.8722638821913...|\n",
      "|[20.0,10920.0,6.0...|[0.0,0.0,0.0,0.0,...|157000| [-0.8722638821913...|\n",
      "|[45.0,6120.0,7.0,...|[1.0,21.0,0.0,0.0...|132000| [-0.2812553115586...|\n",
      "|[20.0,11241.0,6.0...|[0.0,0.0,0.0,0.0,...|149000| [-0.8722638821913...|\n",
      "|[90.0,10791.0,4.0...|[0.0,17.0,0.0,0.0...| 90000| [0.78256011558026...|\n",
      "|[20.0,13695.0,5.0...|[0.0,20.0,0.0,0.0...|159000| [-0.8722638821913...|\n",
      "|[20.0,7560.0,5.0,...|[0.0,2.0,0.0,0.0,...|139000| [-0.8722638821913...|\n",
      "+--------------------+--------------------+------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StandardScaler\n",
    "import org.apache.spark.ml.linalg.DenseVector\n",
    "\n",
    "val scaler = new StandardScaler().setInputCol(\"feature_scaler\").setOutputCol(\"feature_scaler_scaled\").setWithMean(true).setWithStd(true)\n",
    "val data_scaled = scaler.fit(data).transform(data)\n",
    "data_scaled.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Combing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> how does __++__ works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(i, love, you, i, love, you)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List(\"i\", \"love\", \"you\")++List(\"i\", \"love\", \"you\") // integrated as one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features| label|\n",
      "+--------------------+------+\n",
      "|[0.07334983082099...|208500|\n",
      "|[-0.8722638821913...|181500|\n",
      "|[0.07334983082099...|223500|\n",
      "|[0.30975325907408...|140000|\n",
      "|[0.07334983082099...|250000|\n",
      "|[-0.1630535974320...|143000|\n",
      "|[-0.8722638821913...|307000|\n",
      "|[0.07334983082099...|200000|\n",
      "|[-0.1630535974320...|129900|\n",
      "|[3.14659439811116...|118000|\n",
      "|[-0.8722638821913...|129500|\n",
      "|[0.07334983082099...|345000|\n",
      "|[-0.8722638821913...|144000|\n",
      "|[-0.8722638821913...|279500|\n",
      "|[-0.8722638821913...|157000|\n",
      "|[-0.2812553115586...|132000|\n",
      "|[-0.8722638821913...|149000|\n",
      "|[0.78256011558026...| 90000|\n",
      "|[-0.8722638821913...|159000|\n",
      "|[-0.8722638821913...|139000|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0733498308209927,-0.20707075668205258,0.6512560957790647,-0.5170226533860203,1.0506337978673879,0.8783671227330037,0.575227739911998,-0.2885539604701559,-0.9442670603932537,-0.4591452184971245,-0.7931620228890606,1.1614536249333418,-0.12020053800860224,0.37020659097218805,1.107430697123042,-0.24097846650905155,0.7894700167005669,1.2271648985501917,0.16372301852733478,-0.21138115318786865,0.9118973170421597,-0.9509006699369583,0.31161787088170956,0.35088009468698733,-0.751918199272585,0.2164290032203515,-0.35920182285425667,-0.11629943710230334,-0.27011580124313367,-0.06866821893757226,-0.0876577763013636,-1.5985633645864097,0.13872995427158735,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,21.0,1.0,0.0,0.0,1.0,0.0,0.0,1...."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_ready = data_scaled.map{row => \n",
    "    val combinedFeatures = Vectors.dense(\n",
    "        row.getAs[DenseVector](\"feature_scaler_scaled\").values ++ \n",
    "        row.getAs[DenseVector](\"feature_categorical\").values\n",
    "    )\n",
    "    (combinedFeatures, row.getAs[Int](\"label\"))\n",
    "    }.toDF(\"features\", \"label\")\n",
    "data_ready.show\n",
    "data_ready.select(\"features\").first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "MSSubClass\n",
      "LotArea\n",
      "OverallQual\n",
      "OverallCond\n",
      "YearBuilt\n",
      "YearRemodAdd\n",
      "BsmtFinSF1\n",
      "BsmtFinSF2\n",
      "BsmtUnfSF\n",
      "TotalBsmtSF\n",
      "1stFlrSF\n",
      "2ndFlrSF\n",
      "LowQualFinSF\n",
      "GrLivArea\n",
      "BsmtFullBath\n",
      "BsmtHalfBath\n",
      "FullBath\n",
      "HalfBath\n",
      "BedroomAbvGr\n",
      "KitchenAbvGr\n",
      "TotRmsAbvGrd\n",
      "Fireplaces\n",
      "GarageCars\n",
      "GarageArea\n",
      "WoodDeckSF\n",
      "OpenPorchSF\n",
      "EnclosedPorch\n",
      "3SsnPorch\n",
      "ScreenPorch\n",
      "PoolArea\n",
      "MiscVal\n",
      "MoSold\n",
      "YrSold\n",
      "+--------------------+------+\n",
      "|     scalar_features|labels|\n",
      "+--------------------+------+\n",
      "|[1.0,60.0,8450.0,...|208500|\n",
      "|[2.0,20.0,9600.0,...|181500|\n",
      "|[3.0,60.0,11250.0...|223500|\n",
      "|[4.0,70.0,9550.0,...|140000|\n",
      "|[5.0,60.0,14260.0...|250000|\n",
      "|[6.0,50.0,14115.0...|143000|\n",
      "|[7.0,20.0,10084.0...|307000|\n",
      "|[8.0,60.0,10382.0...|200000|\n",
      "|[9.0,50.0,6120.0,...|129900|\n",
      "|[10.0,190.0,7420....|118000|\n",
      "|[11.0,20.0,11200....|129500|\n",
      "|[12.0,60.0,11924....|345000|\n",
      "|[13.0,20.0,12968....|144000|\n",
      "|[14.0,20.0,10652....|279500|\n",
      "|[15.0,20.0,10920....|157000|\n",
      "|[16.0,45.0,6120.0...|132000|\n",
      "|[17.0,20.0,11241....|149000|\n",
      "|[18.0,90.0,10791....| 90000|\n",
      "|[19.0,20.0,13695....|159000|\n",
      "|[20.0,20.0,7560.0...|139000|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+------+\n",
      "|            features|labels|\n",
      "+--------------------+------+\n",
      "|[60.0,8450.0,7.0,...|208500|\n",
      "|[20.0,9600.0,6.0,...|181500|\n",
      "|[60.0,11250.0,7.0...|223500|\n",
      "|[70.0,9550.0,7.0,...|140000|\n",
      "|[60.0,14260.0,8.0...|250000|\n",
      "|[50.0,14115.0,5.0...|143000|\n",
      "|[20.0,10084.0,8.0...|307000|\n",
      "|[60.0,10382.0,7.0...|200000|\n",
      "|[50.0,6120.0,7.0,...|129900|\n",
      "|[190.0,7420.0,5.0...|118000|\n",
      "|[20.0,11200.0,5.0...|129500|\n",
      "|[60.0,11924.0,9.0...|345000|\n",
      "|[20.0,12968.0,5.0...|144000|\n",
      "|[20.0,10652.0,7.0...|279500|\n",
      "|[20.0,10920.0,6.0...|157000|\n",
      "|[45.0,6120.0,7.0,...|132000|\n",
      "|[20.0,11241.0,6.0...|149000|\n",
      "|[90.0,10791.0,4.0...| 90000|\n",
      "|[20.0,13695.0,5.0...|159000|\n",
      "|[20.0,7560.0,5.0,...|139000|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorSlicer\n",
    "\n",
    "val scalarField: Seq[String] = df.schema.fields.collect{ case StructField(name, IntegerType,_,_)\n",
    "        if name != labelField => name\n",
    "}\n",
    "scalarField.foreach(println)\n",
    "\n",
    "val scalarData = df.map{ row =>(\n",
    "    Vectors.dense(scalarField.map(name=>row.getAs[Int](name).toDouble).toArray),\n",
    "    row.getInt(row.fieldIndex(labelField))\n",
    ")}.toDF(\"scalar_features\", \"labels\")\n",
    "\n",
    "scalarData.show\n",
    "\n",
    "// get rid of the features of the first 2 columns\n",
    "val slicer = new VectorSlicer().setInputCol(\"scalar_features\").setOutputCol(\"features\").setIndices((1 until scalarField.size).toArray)\n",
    "\n",
    "val output = slicer.transform(scalarData)\n",
    "val dataCombined = output.select(\"features\", \"labels\")\n",
    "dataCombined.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.regression.{LinearRegression, DecisionTreeRegressor}\n",
    "import org.apache.spark.ml.Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown Error\n",
       "Message: <console>:51: error: not found: type DataFrame\n",
       "       def evaluate(ds:DataFrame, model:Transformer)={\n",
       "                       ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainData, testData) = dataCombined.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "def evaluate(ds, model)={\n",
    "    val evaluator = new RegressionEvaluator()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
