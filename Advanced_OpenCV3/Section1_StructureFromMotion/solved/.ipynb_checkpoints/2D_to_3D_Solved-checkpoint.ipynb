{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Testing the development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version 3.1.0\n",
      "Numpy version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Checking the OpenCV version\n",
    "print(\"OpenCV version\", cv2.__version__)\n",
    "\n",
    "# Checking the Numpy version\n",
    "print(\"Numpy version\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Markov Random Field\n",
    "\n",
    "Markov Random Fields (MRFs), is a formulation which is widely used in generative image modeling.\n",
    "\n",
    "> Link: An MRF Deep Learning to model to to express the complex interactions among pixels.\n",
    "http://dahua.me/publications/dhl16_deepmrf.pdf\n",
    "\n",
    "Lets see an example of Markov Random Field to denoise an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609485626221\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAEICAYAAAC9P1pMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f921804e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f923e1055c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image denoising using MRF model\n",
    "from PIL import Image\n",
    "import numpy\n",
    "from pylab import *\n",
    "\n",
    "def MRF_denoise(noisy):\n",
    "    # Start MRF\n",
    "    (M,N)=noisy.shape\n",
    "    y_old=noisy\n",
    "    y=zeros((M,N))\n",
    "\n",
    "    while(SNR(y_old,y)>0.01):\n",
    "        print(SNR(y_old,y))\n",
    "        for i in range(M):\n",
    "            for j in range(N):\n",
    "                index=neighbor(i,j,M,N)\n",
    "\n",
    "                a=cost(1,noisy[i,j],y_old,index)\n",
    "                b=cost(0,noisy[i,j],y_old,index)\n",
    "\n",
    "                if a>b:\n",
    "                    y[i,j]=1\n",
    "                else:\n",
    "                    y[i,j]=0\n",
    "        y_old=yield\n",
    "    print(SNR(y_old,y))\n",
    "    return y\n",
    "\n",
    "def SNR(A,B):\n",
    "    if A.shape==B.shape:\n",
    "        return numpy.sum(numpy.abs(A-B))/A.size\n",
    "    else:\n",
    "        raise Exception(\"Two matrices must have the same size!\")\n",
    "\n",
    "def delta(a,b):\n",
    "    if (a==b):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def neighbor(i,j,M,N):\n",
    "\t#find correct neighbors\n",
    "\tif (i==0 and j==0):\n",
    "\t\tneighbor=[(0,1), (1,0)]\n",
    "\telif i==0 and j==N-1:\n",
    "\t\tneighbor=[(0,N-2), (1,N-1)]\n",
    "\telif i==M-1 and j==0:\n",
    "\t\tneighbor=[(M-1,1), (M-2,0)]\n",
    "\telif i==M-1 and j==N-1:\n",
    "\t\tneighbor=[(M-1,N-2), (M-2,N-1)]\n",
    "\telif i==0:\n",
    "\t\tneighbor=[(0,j-1), (0,j+1), (1,j)]\n",
    "\telif i==M-1:\n",
    "\t\tneighbor=[(M-1,j-1), (M-1,j+1), (M-2,j)]\n",
    "\telif j==0:\n",
    "\t\tneighbor=[(i-1,0), (i+1,0), (i,1)]\n",
    "\telif j==N-1:\n",
    "\t\tneighbor=[(i-1,N-1), (i+1,N-1), (i,N-2)]\n",
    "\telse:\n",
    "\t\tneighbor=[(i-1,j), (i+1,j), (i,j-1), (i,j+1),\\\n",
    "\t\t\t\t  (i-1,j-1), (i-1,j+1), (i+1,j-1), (i+1,j+1)]\n",
    "\treturn neighbor\n",
    "\n",
    "def cost(y,x,y_old,index):\n",
    "    alpha=1\n",
    "    beta=10\n",
    "    return alpha*delta(y,x)+\\\n",
    "        beta*sum(delta(y,y_old[i]) for i in index)\n",
    "\n",
    "# Read in image\n",
    "im=Image.open('../images/lena512.bmp')\n",
    "im=numpy.array(im)\n",
    "im=where (im>100,1,0) #convert to binary image\n",
    "(M,N)=im.shape\n",
    "\n",
    "# Add noise\n",
    "noisy=im.copy()\n",
    "noise=numpy.random.rand(M,N)\n",
    "ind=where(noise<0.2)\n",
    "noisy[ind]=1-noisy[ind]\n",
    "\n",
    "gray()\n",
    "title('Noisy Image')\n",
    "imshow(noisy)\n",
    "\n",
    "out=MRF_denoise(noisy)\n",
    "\n",
    "figure()\n",
    "gray()\n",
    "title('Denoised Image')\n",
    "print(next(out))\n",
    "#print()\n",
    "#imshow(next(out))\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predicting Depth in Images\n",
    "\n",
    "We will see a CNN model trained for depth prediction from a single RGB image, as described in the paper \"Deeper Depth Prediction with Fully Convolutional Residual Networks\".\n",
    "\n",
    "Paper Link: https://arxiv.org/pdf/1606.00373.pdf\n",
    "\n",
    "\n",
    "#### Information of CNN\n",
    "\n",
    "1. Theory\n",
    "http://colah.github.io/posts/2014-07-Understanding-Convolutions/\n",
    "http://cs231n.github.io/\n",
    "\n",
    "2. CNN - Tensorflow\n",
    "https://www.tensorflow.org/tutorials/deep_cnn\n",
    "\n",
    "#### Information on Residual Networks\n",
    "\n",
    "1. https://wiseodd.github.io/techblog/2016/10/13/residual-net/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Creating the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Commonly used layers and operations based on ethereon's implementation \n",
    "# https://github.com/ethereon/caffe-tensorflow\n",
    "# Slight modifications may apply. FCRN-specific operations have also been appended. \n",
    "# ----------------------------------------------------------------------------------\n",
    "# Thanks to *Helisa Dhamo* for the model conversion and integration into TensorFlow.\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "DEFAULT_PADDING = 'SAME'\n",
    "\n",
    "\n",
    "def get_incoming_shape(incoming):\n",
    "    \"\"\" Returns the incoming data shape \"\"\"\n",
    "    if isinstance(incoming, tf.Tensor):\n",
    "        return incoming.get_shape().as_list()\n",
    "    elif type(incoming) in [np.array, list, tuple]:\n",
    "        return np.shape(incoming)\n",
    "    else:\n",
    "        raise Exception(\"Invalid incoming layer.\")\n",
    "\n",
    "\n",
    "def interleave(tensors, axis):\n",
    "    old_shape = get_incoming_shape(tensors[0])[1:]\n",
    "    new_shape = [-1] + old_shape\n",
    "    new_shape[axis] *= len(tensors)\n",
    "    return tf.reshape(tf.stack(tensors, axis + 1), new_shape)\n",
    "\n",
    "def layer(op):\n",
    "    '''Decorator for composable network layers.'''\n",
    "\n",
    "    def layer_decorated(self, *args, **kwargs):\n",
    "        # Automatically set a name if not provided.\n",
    "        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))\n",
    "\n",
    "        # Figure out the layer inputs.\n",
    "        if len(self.terminals) == 0:\n",
    "            raise RuntimeError('No input variables found for layer %s.' % name)\n",
    "        elif len(self.terminals) == 1:\n",
    "            layer_input = self.terminals[0]\n",
    "        else:\n",
    "            layer_input = list(self.terminals)\n",
    "        # Perform the operation and get the output.\n",
    "        layer_output = op(self, layer_input, *args, **kwargs)\n",
    "        # Add to layer LUT.\n",
    "        self.layers[name] = layer_output\n",
    "        # This output is now the input for the next layer.\n",
    "        self.feed(layer_output)\n",
    "        # Return self for chained calls.\n",
    "        return self\n",
    "\n",
    "    return layer_decorated\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, inputs, batch, keep_prob, is_training, trainable = True):\n",
    "        # The input nodes for this network\n",
    "        self.inputs = inputs\n",
    "        # The current list of terminal nodes\n",
    "        self.terminals = []\n",
    "        # Mapping from layer names to layers\n",
    "        self.layers = dict(inputs)\n",
    "        # If true, the resulting variables are set as trainable\n",
    "        self.trainable = trainable\n",
    "        self.batch_size = batch\n",
    "        self.keep_prob = keep_prob\n",
    "        self.is_training = is_training\n",
    "        self.setup()\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        '''Construct the network. '''\n",
    "        raise NotImplementedError('Must be implemented by the subclass.')\n",
    "\n",
    "    def load(self, data_path, session, ignore_missing=False):\n",
    "        '''Load network weights.\n",
    "        data_path: The path to the numpy-serialized network weights\n",
    "        session: The current TensorFlow session\n",
    "        ignore_missing: If true, serialized weights for missing layers are ignored.\n",
    "        '''\n",
    "        data_dict = np.load(data_path, encoding='latin1').item()\n",
    "        for op_name in data_dict: \n",
    "            with tf.variable_scope(op_name, reuse=True):\n",
    "                for param_name, data in iter(data_dict[op_name].items()):      \n",
    "                    try:\n",
    "                        var = tf.get_variable(param_name)\n",
    "                        session.run(var.assign(data))\n",
    "\n",
    "                    except ValueError:\n",
    "                        if not ignore_missing:\n",
    "                            raise\n",
    "\n",
    "    def feed(self, *args):\n",
    "        '''Set the input(s) for the next operation by replacing the terminal nodes.\n",
    "        The arguments can be either layer names or the actual layers.\n",
    "        '''\n",
    "        assert len(args) != 0\n",
    "        self.terminals = []\n",
    "        for fed_layer in args:\n",
    "            if isinstance(fed_layer, str):\n",
    "                try:\n",
    "                    fed_layer = self.layers[fed_layer]\n",
    "                except KeyError:\n",
    "                    raise KeyError('Unknown layer name fed: %s' % fed_layer)\n",
    "            self.terminals.append(fed_layer)\n",
    "        return self\n",
    "\n",
    "    def get_output(self):\n",
    "        '''Returns the current network output.'''\n",
    "        return self.terminals[-1]\n",
    "\n",
    "    def get_layer_output(self, name):\n",
    "        return self.layers[name]\n",
    "\n",
    "    def get_unique_name(self, prefix):\n",
    "        '''Returns an index-suffixed unique name for the given prefix.\n",
    "        This is used for auto-generating layer names based on the type-prefix.\n",
    "        '''\n",
    "        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n",
    "        return '%s_%d' % (prefix, ident)\n",
    "\n",
    "    def make_var(self, name, shape):\n",
    "        '''Creates a new TensorFlow variable.'''\n",
    "        return tf.get_variable(name, shape, dtype = 'float32', trainable=self.trainable)\n",
    "\n",
    "    def validate_padding(self, padding):\n",
    "        '''Verifies that the padding is one of the supported ones.'''\n",
    "        assert padding in ('SAME', 'VALID')\n",
    "\n",
    "    @layer\n",
    "    def conv(self,\n",
    "             input_data,\n",
    "             k_h,\n",
    "             k_w,\n",
    "             c_o,\n",
    "             s_h,\n",
    "             s_w,\n",
    "             name,\n",
    "             relu=True,\n",
    "             padding=DEFAULT_PADDING,\n",
    "             group=1,\n",
    "             biased=True):\n",
    "\n",
    "        # Verify that the padding is acceptable\n",
    "        self.validate_padding(padding)\n",
    "        # Get the number of channels in the input\n",
    "        c_i = input_data.get_shape()[-1]\n",
    "\n",
    "        if (padding == 'SAME'):\n",
    "            input_data = tf.pad(input_data, [[0, 0], [(k_h - 1)//2, (k_h - 1)//2], [(k_w - 1)//2, (k_w - 1)//2], [0, 0]], \"CONSTANT\")\n",
    "        \n",
    "        # Verify that the grouping parameter is valid\n",
    "        assert c_i % group == 0\n",
    "        assert c_o % group == 0\n",
    "        # Convolution for a given input and kernel\n",
    "        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding='VALID')\n",
    "        \n",
    "        with tf.variable_scope(name) as scope:\n",
    "            kernel = self.make_var('weights', shape=[k_h, k_w, c_i // group, c_o])\n",
    "\n",
    "            if group == 1:\n",
    "                # This is the common-case. Convolve the input without any further complications.\n",
    "                output = convolve(input_data, kernel)\n",
    "            else:\n",
    "                # Split the input into groups and then convolve each of them independently\n",
    "\n",
    "                input_groups = tf.split(3, group, input_data)\n",
    "                kernel_groups = tf.split(3, group, kernel)\n",
    "                output_groups = [convolve(i, k) for i, k in zip(input_groups, kernel_groups)]\n",
    "                # Concatenate the groups\n",
    "                output = tf.concat(3, output_groups)\n",
    "\n",
    "            # Add the biases\n",
    "            if biased:\n",
    "                biases = self.make_var('biases', [c_o])\n",
    "                output = tf.nn.bias_add(output, biases)\n",
    "            if relu:\n",
    "                # ReLU non-linearity\n",
    "                output = tf.nn.relu(output, name=scope.name)\n",
    "\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def relu(self, input_data, name):\n",
    "        return tf.nn.relu(input_data, name=name)\n",
    "\n",
    "    @layer\n",
    "    def max_pool(self, input_data, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.max_pool(input_data,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def avg_pool(self, input_data, k_h, k_w, s_h, s_w, name, padding=DEFAULT_PADDING):\n",
    "        self.validate_padding(padding)\n",
    "        return tf.nn.avg_pool(input_data,\n",
    "                              ksize=[1, k_h, k_w, 1],\n",
    "                              strides=[1, s_h, s_w, 1],\n",
    "                              padding=padding,\n",
    "                              name=name)\n",
    "\n",
    "    @layer\n",
    "    def lrn(self, input_data, radius, alpha, beta, name, bias=1.0):\n",
    "        return tf.nn.local_response_normalization(input_data,\n",
    "                                                  depth_radius=radius,\n",
    "                                                  alpha=alpha,\n",
    "                                                  beta=beta,\n",
    "                                                  bias=bias,\n",
    "                                                  name=name)\n",
    "\n",
    "    @layer\n",
    "    def concat(self, inputs, axis, name):\n",
    "        return tf.concat(concat_dim=axis, values=inputs, name=name)\n",
    "\n",
    "    @layer\n",
    "    def add(self, inputs, name):\n",
    "        return tf.add_n(inputs, name=name)\n",
    "\n",
    "    @layer\n",
    "    def fc(self, input_data, num_out, name, relu=True):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            input_shape = input_data.get_shape()\n",
    "            if input_shape.ndims == 4:\n",
    "                # The input is spatial. Vectorize it first.\n",
    "                dim = 1\n",
    "                for d in input_shape[1:].as_list():\n",
    "                    dim *= d\n",
    "                feed_in = tf.reshape(input_data, [-1, dim])\n",
    "            else:\n",
    "                feed_in, dim = (input_data, input_shape[-1].value)\n",
    "            weights = self.make_var('weights', shape=[dim, num_out])\n",
    "            biases = self.make_var('biases', [num_out])\n",
    "            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n",
    "            fc = op(feed_in, weights, biases, name=scope.name)\n",
    "            return fc\n",
    "\n",
    "    @layer\n",
    "    def softmax(self, input_data, name):\n",
    "        input_shape = map(lambda v: v.value, input_data.get_shape())\n",
    "        if len(input_shape) > 2:\n",
    "            # For certain models (like NiN), the singleton spatial dimensions\n",
    "            # need to be explicitly squeezed, since they're not broadcast-able\n",
    "            # in TensorFlow's NHWC ordering (unlike Caffe's NCHW).\n",
    "            if input_shape[1] == 1 and input_shape[2] == 1:\n",
    "                input_data = tf.squeeze(input_data, squeeze_dims=[1, 2])\n",
    "            else:\n",
    "                raise ValueError('Rank 2 tensor input expected for softmax!')\n",
    "        return tf.nn.softmax(input_data, name)\n",
    "\n",
    "    @layer\n",
    "    def batch_normalization(self, input_data, name, scale_offset=True, relu=False):\n",
    "\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            shape = [input_data.get_shape()[-1]]\n",
    "            pop_mean = tf.get_variable(\"mean\", shape, initializer = tf.constant_initializer(0.0), trainable=False)\n",
    "            pop_var = tf.get_variable(\"variance\", shape, initializer = tf.constant_initializer(1.0), trainable=False)\n",
    "            epsilon = 1e-4\n",
    "            decay = 0.999\n",
    "            if scale_offset:\n",
    "                scale = tf.get_variable(\"scale\", shape, initializer = tf.constant_initializer(1.0))\n",
    "                offset = tf.get_variable(\"offset\", shape, initializer = tf.constant_initializer(0.0))\n",
    "            else:\n",
    "                scale, offset = (None, None)\n",
    "            if self.is_training:\n",
    "                batch_mean, batch_var = tf.nn.moments(input_data, [0, 1, 2])\n",
    "\n",
    "                train_mean = tf.assign(pop_mean,\n",
    "                               pop_mean * decay + batch_mean * (1 - decay))\n",
    "                train_var = tf.assign(pop_var,\n",
    "                              pop_var * decay + batch_var * (1 - decay))\n",
    "                with tf.control_dependencies([train_mean, train_var]):\n",
    "                    output = tf.nn.batch_normalization(input_data,\n",
    "                    batch_mean, batch_var, offset, scale, epsilon, name = name)\n",
    "            else:\n",
    "                output = tf.nn.batch_normalization(input_data,\n",
    "                pop_mean, pop_var, offset, scale, epsilon, name = name)\n",
    "\n",
    "            if relu:\n",
    "                output = tf.nn.relu(output)\n",
    "\n",
    "            return output\n",
    "\n",
    "    @layer\n",
    "    def dropout(self, input_data, keep_prob, name):\n",
    "        return tf.nn.dropout(input_data, keep_prob, name=name)\n",
    "    \n",
    "\n",
    "    def unpool_as_conv(self, size, input_data, id, stride = 1, ReLU = False, BN = True):\n",
    "\n",
    "\t\t# Model upconvolutions (unpooling + convolution) as interleaving feature\n",
    "\t\t# maps of four convolutions (A,B,C,D). Building block for up-projections. \n",
    "\n",
    "\n",
    "        # Convolution A (3x3)\n",
    "        # --------------------------------------------------\n",
    "        layerName = \"layer%s_ConvA\" % (id)\n",
    "        self.feed(input_data)\n",
    "        self.conv( 3, 3, size[3], stride, stride, name = layerName, padding = 'SAME', relu = False)\n",
    "        outputA = self.get_output()\n",
    "\n",
    "        # Convolution B (2x3)\n",
    "        # --------------------------------------------------\n",
    "        layerName = \"layer%s_ConvB\" % (id)\n",
    "        padded_input_B = tf.pad(input_data, [[0, 0], [1, 0], [1, 1], [0, 0]], \"CONSTANT\")\n",
    "        self.feed(padded_input_B)\n",
    "        self.conv(2, 3, size[3], stride, stride, name = layerName, padding = 'VALID', relu = False)\n",
    "        outputB = self.get_output()\n",
    "\n",
    "        # Convolution C (3x2)\n",
    "        # --------------------------------------------------\n",
    "        layerName = \"layer%s_ConvC\" % (id)\n",
    "        padded_input_C = tf.pad(input_data, [[0, 0], [1, 1], [1, 0], [0, 0]], \"CONSTANT\")\n",
    "        self.feed(padded_input_C)\n",
    "        self.conv(3, 2, size[3], stride, stride, name = layerName, padding = 'VALID', relu = False)\n",
    "        outputC = self.get_output()\n",
    "\n",
    "        # Convolution D (2x2)\n",
    "        # --------------------------------------------------\n",
    "        layerName = \"layer%s_ConvD\" % (id)\n",
    "        padded_input_D = tf.pad(input_data, [[0, 0], [1, 0], [1, 0], [0, 0]], \"CONSTANT\")\n",
    "        self.feed(padded_input_D)\n",
    "        self.conv(2, 2, size[3], stride, stride, name = layerName, padding = 'VALID', relu = False)\n",
    "        outputD = self.get_output()\n",
    "\n",
    "        # Interleaving elements of the four feature maps\n",
    "        # --------------------------------------------------\n",
    "        left = interleave([outputA, outputB], axis=1)  # columns\n",
    "        right = interleave([outputC, outputD], axis=1)  # columns\n",
    "        Y = interleave([left, right], axis=2) # rows\n",
    "        \n",
    "        if BN:\n",
    "            layerName = \"layer%s_BN\" % (id)\n",
    "            self.feed(Y)\n",
    "            self.batch_normalization(name = layerName, scale_offset = True, relu = False)\n",
    "            Y = self.get_output()\n",
    "\n",
    "        if ReLU:\n",
    "            Y = tf.nn.relu(Y, name = layerName)\n",
    "        \n",
    "        return Y\n",
    "\n",
    "\n",
    "    def up_project(self, size, id, stride = 1, BN = True):\n",
    "        \n",
    "        # Create residual upsampling layer (UpProjection)\n",
    "\n",
    "        input_data = self.get_output()\n",
    "\n",
    "        # Branch 1\n",
    "        id_br1 = \"%s_br1\" % (id)\n",
    "\n",
    "        # Interleaving Convs of 1st branch\n",
    "        out = self.unpool_as_conv(size, input_data, id_br1, stride, ReLU=True, BN=True)\n",
    "\n",
    "        # Convolution following the upProjection on the 1st branch\n",
    "        layerName = \"layer%s_Conv\" % (id)\n",
    "        self.feed(out)\n",
    "        self.conv(size[0], size[1], size[3], stride, stride, name = layerName, relu = False)\n",
    "\n",
    "        if BN:\n",
    "            layerName = \"layer%s_BN\" % (id)\n",
    "            self.batch_normalization(name = layerName, scale_offset=True, relu = False)\n",
    "\n",
    "        # Output of 1st branch\n",
    "        branch1_output = self.get_output()\n",
    "\n",
    "            \n",
    "        # Branch 2\n",
    "        id_br2 = \"%s_br2\" % (id)\n",
    "        # Interleaving convolutions and output of 2nd branch\n",
    "        branch2_output = self.unpool_as_conv(size, input_data, id_br2, stride, ReLU=False)\n",
    "\n",
    "        \n",
    "        # sum branches\n",
    "        layerName = \"layer%s_Sum\" % (id)\n",
    "        output = tf.add_n([branch1_output, branch2_output], name = layerName)\n",
    "        # ReLU\n",
    "        layerName = \"layer%s_ReLU\" % (id)\n",
    "        output = tf.nn.relu(output, name=layerName)\n",
    "\n",
    "        self.feed(output)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50UpProj(Network):\n",
    "    def setup(self):\n",
    "        (self.feed('data')\n",
    "             .conv(7, 7, 64, 2, 2, relu=False, name='conv1')\n",
    "             .batch_normalization(relu=True, name='bn_conv1')\n",
    "             .max_pool(3, 3, 2, 2, name='pool1')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch1')\n",
    "             .batch_normalization(name='bn2a_branch1'))\n",
    "\n",
    "        (self.feed('pool1')\n",
    "             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2a_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn2a_branch2a')\n",
    "             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2a_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn2a_branch2b')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2a_branch2c')\n",
    "             .batch_normalization(name='bn2a_branch2c'))\n",
    "\n",
    "        (self.feed('bn2a_branch1',\n",
    "                   'bn2a_branch2c')\n",
    "             .add(name='res2a')\n",
    "             .relu(name='res2a_relu')\n",
    "             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2b_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn2b_branch2a')\n",
    "             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2b_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn2b_branch2b')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2b_branch2c')\n",
    "             .batch_normalization(name='bn2b_branch2c'))\n",
    "\n",
    "        (self.feed('res2a_relu',\n",
    "                   'bn2b_branch2c')\n",
    "             .add(name='res2b')\n",
    "             .relu(name='res2b_relu')\n",
    "             .conv(1, 1, 64, 1, 1, biased=False, relu=False, name='res2c_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn2c_branch2a')\n",
    "             .conv(3, 3, 64, 1, 1, biased=False, relu=False, name='res2c_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn2c_branch2b')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res2c_branch2c')\n",
    "             .batch_normalization(name='bn2c_branch2c'))\n",
    "\n",
    "        (self.feed('res2b_relu',\n",
    "                   'bn2c_branch2c')\n",
    "             .add(name='res2c')\n",
    "             .relu(name='res2c_relu')\n",
    "             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res3a_branch1')\n",
    "             .batch_normalization(name='bn3a_branch1'))\n",
    "\n",
    "        (self.feed('res2c_relu')\n",
    "             .conv(1, 1, 128, 2, 2, biased=False, relu=False, name='res3a_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn3a_branch2a')\n",
    "             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3a_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn3a_branch2b')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3a_branch2c')\n",
    "             .batch_normalization(name='bn3a_branch2c'))\n",
    "\n",
    "        (self.feed('bn3a_branch1',\n",
    "                   'bn3a_branch2c')\n",
    "             .add(name='res3a')\n",
    "             .relu(name='res3a_relu')\n",
    "             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3b_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn3b_branch2a')\n",
    "             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3b_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn3b_branch2b')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3b_branch2c')\n",
    "             .batch_normalization(name='bn3b_branch2c'))\n",
    "\n",
    "        (self.feed('res3a_relu',\n",
    "                   'bn3b_branch2c')\n",
    "             .add(name='res3b')\n",
    "             .relu(name='res3b_relu')\n",
    "             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3c_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn3c_branch2a')\n",
    "             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3c_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn3c_branch2b')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3c_branch2c')\n",
    "             .batch_normalization(name='bn3c_branch2c'))\n",
    "\n",
    "        (self.feed('res3b_relu',\n",
    "                   'bn3c_branch2c')\n",
    "             .add(name='res3c')\n",
    "             .relu(name='res3c_relu')\n",
    "             .conv(1, 1, 128, 1, 1, biased=False, relu=False, name='res3d_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn3d_branch2a')\n",
    "             .conv(3, 3, 128, 1, 1, biased=False, relu=False, name='res3d_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn3d_branch2b')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res3d_branch2c')\n",
    "             .batch_normalization(name='bn3d_branch2c'))\n",
    "\n",
    "        (self.feed('res3c_relu',\n",
    "                   'bn3d_branch2c')\n",
    "             .add(name='res3d')\n",
    "             .relu(name='res3d_relu')\n",
    "             .conv(1, 1, 1024, 2, 2, biased=False, relu=False, name='res4a_branch1')\n",
    "             .batch_normalization(name='bn4a_branch1'))\n",
    "\n",
    "        (self.feed('res3d_relu')\n",
    "             .conv(1, 1, 256, 2, 2, biased=False, relu=False, name='res4a_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4a_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4a_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4a_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4a_branch2c')\n",
    "             .batch_normalization(name='bn4a_branch2c'))\n",
    "\n",
    "        (self.feed('bn4a_branch1',\n",
    "                   'bn4a_branch2c')\n",
    "             .add(name='res4a')\n",
    "             .relu(name='res4a_relu')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4b_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4b_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4b_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4b_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4b_branch2c')\n",
    "             .batch_normalization(name='bn4b_branch2c'))\n",
    "\n",
    "        (self.feed('res4a_relu',\n",
    "                   'bn4b_branch2c')\n",
    "             .add(name='res4b')\n",
    "             .relu(name='res4b_relu')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4c_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4c_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4c_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4c_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4c_branch2c')\n",
    "             .batch_normalization(name='bn4c_branch2c'))\n",
    "\n",
    "        (self.feed('res4b_relu',\n",
    "                   'bn4c_branch2c')\n",
    "             .add(name='res4c')\n",
    "             .relu(name='res4c_relu')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4d_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4d_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4d_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4d_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4d_branch2c')\n",
    "             .batch_normalization(name='bn4d_branch2c'))\n",
    "\n",
    "        (self.feed('res4c_relu',\n",
    "                   'bn4d_branch2c')\n",
    "             .add(name='res4d')\n",
    "             .relu(name='res4d_relu')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4e_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4e_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4e_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4e_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4e_branch2c')\n",
    "             .batch_normalization(name='bn4e_branch2c'))\n",
    "\n",
    "        (self.feed('res4d_relu',\n",
    "                   'bn4e_branch2c')\n",
    "             .add(name='res4e')\n",
    "             .relu(name='res4e_relu')\n",
    "             .conv(1, 1, 256, 1, 1, biased=False, relu=False, name='res4f_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn4f_branch2a')\n",
    "             .conv(3, 3, 256, 1, 1, biased=False, relu=False, name='res4f_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn4f_branch2b')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=False, relu=False, name='res4f_branch2c')\n",
    "             .batch_normalization(name='bn4f_branch2c'))\n",
    "\n",
    "        (self.feed('res4e_relu',\n",
    "                   'bn4f_branch2c')\n",
    "             .add(name='res4f')\n",
    "             .relu(name='res4f_relu')\n",
    "             .conv(1, 1, 2048, 2, 2, biased=False, relu=False, name='res5a_branch1')\n",
    "             .batch_normalization(name='bn5a_branch1'))\n",
    "\n",
    "        (self.feed('res4f_relu')\n",
    "             .conv(1, 1, 512, 2, 2, biased=False, relu=False, name='res5a_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn5a_branch2a')\n",
    "             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5a_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn5a_branch2b')\n",
    "             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5a_branch2c')\n",
    "             .batch_normalization(name='bn5a_branch2c'))\n",
    "\n",
    "        (self.feed('bn5a_branch1',\n",
    "                   'bn5a_branch2c')\n",
    "             .add(name='res5a')\n",
    "             .relu(name='res5a_relu')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5b_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn5b_branch2a')\n",
    "             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5b_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn5b_branch2b')\n",
    "             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5b_branch2c')\n",
    "             .batch_normalization(name='bn5b_branch2c'))\n",
    "\n",
    "        (self.feed('res5a_relu',\n",
    "                   'bn5b_branch2c')\n",
    "             .add(name='res5b')\n",
    "             .relu(name='res5b_relu')\n",
    "             .conv(1, 1, 512, 1, 1, biased=False, relu=False, name='res5c_branch2a')\n",
    "             .batch_normalization(relu=True, name='bn5c_branch2a')\n",
    "             .conv(3, 3, 512, 1, 1, biased=False, relu=False, name='res5c_branch2b')\n",
    "             .batch_normalization(relu=True, name='bn5c_branch2b')\n",
    "             .conv(1, 1, 2048, 1, 1, biased=False, relu=False, name='res5c_branch2c')\n",
    "             .batch_normalization(name='bn5c_branch2c'))\n",
    "\n",
    "        (self.feed('res5b_relu',\n",
    "                   'bn5c_branch2c')\n",
    "             .add(name='res5c')\n",
    "             .relu(name='res5c_relu')\n",
    "             .conv(1, 1, 1024, 1, 1, biased=True, relu=False, name='layer1')\n",
    "             .batch_normalization(relu=False, name='layer1_BN')\n",
    "             .up_project([3, 3, 1024, 512], id = '2x', stride = 1, BN=True)\n",
    "             .up_project([3, 3, 512, 256], id = '4x', stride = 1, BN=True)\n",
    "             .up_project([3, 3, 256, 128], id = '8x', stride = 1, BN=True)\n",
    "             .up_project([3, 3, 128, 64], id = '16x', stride = 1, BN=True)\n",
    "             .dropout(name = 'drop', keep_prob = 1.)\n",
    "             .conv(3, 3, 1, 1, 1, name = 'ConvPred'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth Prediction Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model\n",
      "INFO:tensorflow:Restoring parameters from ../data/NYU_FCRN-checkpoint/NYU_FCRN.ckpt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3ea53ce19992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Predict the image and Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3ea53ce19992>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model_data_path, image_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3157\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3158\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5122\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5124\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5125\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    598\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[1;32m    599\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "def predict(model_data_path, image_path):\n",
    "\n",
    "    # Default input size\n",
    "    height = 228\n",
    "    width = 304\n",
    "    channels = 3\n",
    "    batch_size = 1\n",
    "   \n",
    "    # Read image\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize([width,height], Image.ANTIALIAS)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img = np.expand_dims(np.asarray(img), axis = 0)\n",
    "   \n",
    "    # Create a placeholder for the input image\n",
    "    input_node = tf.placeholder(tf.float32, shape=(None, height, width, channels))\n",
    "\n",
    "    # Construct the network\n",
    "    net = ResNet50UpProj({'data': input_node}, batch_size, 1, False)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Load the converted parameters\n",
    "        print('Loading the model')\n",
    "\n",
    "        # Use to load from ckpt file\n",
    "        saver = tf.train.Saver()     \n",
    "        saver.restore(sess, model_data_path)\n",
    "\n",
    "        # Use to load from npy file\n",
    "        #net.load(model_data_path, sess) \n",
    "\n",
    "        # Evalute the network for the given image\n",
    "        pred = sess.run(net.get_output(), feed_dict={input_node: img})\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.imshow(mpimg.imread(image_path))\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot result\n",
    "        fig = plt.figure()\n",
    "        ii = plt.imshow(pred[0,:,:,0], interpolation='nearest')\n",
    "        fig.colorbar(ii)\n",
    "        plt.show()\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "                \n",
    "model_path = os.path.join(\"..\",\"data\",\"NYU_FCRN-checkpoint\",\"NYU_FCRN.ckpt\")      # Converted parameters for the model\n",
    "image_paths = os.path.join(\"..\",\"images\",\"2D-3D\",\"lab_image.jpeg\") # Directory of images to predict\n",
    "\n",
    "# Predict the image and Plot\n",
    "pred = predict(model_path, image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
